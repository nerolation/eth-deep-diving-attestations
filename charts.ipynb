{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf328e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import signal\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import imgkit\n",
    "from scipy.stats import gaussian_kde\n",
    "from joypy import joyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import font_manager\n",
    "from PIL import Image\n",
    "import matplotlib.patches as mpatches\n",
    "import pytz\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "from helpers import * \n",
    "from xatu import *\n",
    "\n",
    "WHAT = \"head\"\n",
    "DATA = \"data2\"\n",
    "TMP = \"tmp\"\n",
    "IMAGE = f\"{DATA}/images\"\n",
    "SHOW = True\n",
    "DAYS = 31\n",
    "OVERWRITE = False\n",
    "CREATE_BEST_LIST = True\n",
    "DO_PERFORMERS = False\n",
    "\n",
    "IMAGE_HEIGHT = 530\n",
    "FONTSIZE = 19\n",
    "\n",
    "GOOGLE_CREDENTIALS = \"./config/google-creds.json\"\n",
    "\n",
    "FOLDERS_TO_BE_USED = [\"correct_target\"]\n",
    "\n",
    "FONTFAMILY = \"Ubuntu Mono\"\n",
    "\n",
    "for i in FOLDERS_TO_BE_USED:\n",
    "    if not os.path.isdir(f\"{DATA}/{i}\"):\n",
    "        print(\"creating folder \", f\"{DATA}/{i}\")\n",
    "        os.mkdir(f\"{DATA}/{i}\")\n",
    "\n",
    "if not os.path.isdir(f\"{IMAGE}\"):\n",
    "    print(\"creating folder \", f\"{IMAGE}\")\n",
    "    os.mkdir(f\"{IMAGE}\")\n",
    "try:\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS']\n",
    "except:\n",
    "    print(f\"setting google credentials as global variable...\")\n",
    "    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = GOOGLE_CREDENTIALS\n",
    "    \n",
    "stop_requested = False\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    global stop_requested\n",
    "    stop_requested = True\n",
    "    print(\"Graceful shutdown requested...\")\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "signal.signal(signal.SIGTERM, signal_handler)\n",
    "\n",
    "\n",
    "COLORS = [\n",
    "    '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628', '#e41a1c', \n",
    "    '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99', '#cab2d6',\n",
    "    '#1f78b4', '#33a02c', '#ff7f7f'\n",
    "]\n",
    "\n",
    "COLORS2 = [\n",
    "    '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628', '#e41a1c', \n",
    "    '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99', '#cab2d6',\n",
    "    '#1f78b4', '#33a02c', '#ff7f7f', \n",
    "    '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69',\n",
    "    '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f'\n",
    "]\n",
    "\n",
    "COLORS3 = [\n",
    "    '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628',\n",
    "    '#e41a1c', '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99',\n",
    "    '#cab2d6', '#1f78b4', '#33a02c', '#ff7f7f', '#8dd3c7', '#ffffb3',\n",
    "    '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5',\n",
    "    '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f',\n",
    "    '#6a3d9a', '#ffcc00', '#b15928', '#1f78b4', '#e31a1c', '#33a02c',\n",
    "    '#fb9a99', '#e6ab02', '#a6761d', '#666666'\n",
    "]\n",
    "\n",
    "def get_labels(overwrite=False):\n",
    "    try:\n",
    "        if overwrite:\n",
    "            print(\"overwriting...\")\n",
    "            raise\n",
    "        labels = pd.read_parquet(f\"{DATA}/{TMP}/labels.parquet\").drop_duplicates()\n",
    "        print(\"labels read locally\")\n",
    "    except:\n",
    "        print(\"getting labeling info from bq\")\n",
    "        labels = pandas_gbq.read_gbq(\"\"\"\n",
    "            SELECT DISTINCT validator_id, label FROM `ethereum-data-nero.ethdata.beaconchain_validators_db` \n",
    "        \"\"\")\n",
    "        labels.to_parquet(f\"{DATA}/{TMP}/labels.parquet\", index=False)\n",
    "    return labels\n",
    "\n",
    "def get_clients(overwrite=False):\n",
    "    try:\n",
    "        if overwrite:\n",
    "            True\n",
    "        clients = pd.read_parquet(f\"{DATA}/{TMP}/clients_final.parquet\").drop_duplicates()\n",
    "        print(\"get_clients read locally\")\n",
    "    except:\n",
    "        print(\"getting client info from bq\")\n",
    "        clients = pandas_gbq.read_gbq(\"\"\"\n",
    "            SELECT distinct validator_id, cl_client, slot FROM `ethereum-data-nero.ethdata.beaconchain_pace` \n",
    "        \"\"\").drop_duplicates()\n",
    "        clients = clients[clients[\"cl_client\"] != \"missed\"]\n",
    "        clients = clients[clients[\"cl_client\"] != \"Unknown\"]\n",
    "        clients = clients.set_index(\"validator_id\").to_dict()[\"cl_client\"]\n",
    "        pd.DataFrame(list(zip(clients.keys(), clients.values())), columns=[\"validator_id\", \"cl_client\"]).to_parquet(f\"{DATA}/{TMP}/clients_final.parquet\", index=False)\n",
    "        return get_clients(overwrite=False)\n",
    "    return clients\n",
    "\n",
    "def get_clients_with_slots(overwrite=False):\n",
    "    try:\n",
    "        if overwrite:\n",
    "            True\n",
    "        clients = pd.read_parquet(f\"{DATA}/{TMP}/clients_final_with_slot.parquet\").drop_duplicates()\n",
    "        print(\"get_clients read locally\")\n",
    "    except:\n",
    "        print(\"getting client info from bq\")\n",
    "        clients = pandas_gbq.read_gbq(\"\"\"\n",
    "            SELECT distinct validator_id, cl_client, slot FROM `ethereum-data-nero.ethdata.beaconchain_pace` \n",
    "        \"\"\").drop_duplicates()\n",
    "        clients = clients[clients[\"cl_client\"] != \"missed\"]\n",
    "        clients = clients[clients[\"cl_client\"] != \"Unknown\"]\n",
    "        clients.drop_duplicates().to_parquet(f\"{DATA}/{TMP}/clients_final_with_slot.parquet\", index=False)\n",
    "        return get_clients(overwrite=False)\n",
    "    return clients\n",
    "\n",
    "\n",
    "def get_block_sizes(df, overwrite=False):\n",
    "    try:\n",
    "        if overwrite:\n",
    "            raise\n",
    "        size = pd.read_parquet(f\"{DATA}/{TMP}/sizes.parquet\").drop_duplicates()\n",
    "        print(\"get_block_sizes read locally\")\n",
    "    except:\n",
    "        print(\"getting block size info from bq\")\n",
    "        size = pandas_gbq.read_gbq(f\"\"\"\n",
    "            SELECT distinct slot, size, size_compressed, 128*1024*nr_blobs as blobs\n",
    "            FROM `ethereum-data-nero.ethdata.ethereum_blocksize_pace` \n",
    "            where slot >= {df.slot.min()-5} and slot <= {df.slot.max()+5}\n",
    "        \"\"\")\n",
    "        size.to_parquet(f\"{DATA}/{TMP}/sizes.parquet\", index=False)\n",
    "    return size\n",
    "\n",
    "def read_df():\n",
    "    print(f\"reading {DATA}/failed_missed_{WHAT}/failed_missed_data.parquet\")\n",
    "    df = pd.read_parquet(f\"{DATA}/failed_missed_{WHAT}/failed_missed_data.parquet\").drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def add_slot_in_epoch(df):\n",
    "    df[\"slot_in_epoch\"] = df[\"slot\"] % 32\n",
    "    return df\n",
    "\n",
    "def merge_labels(df, labels, left_on=\"validator\", right_on=\"validator_id\", nlargest=15):\n",
    "    df = pd.merge(df, labels, how=\"left\", left_on=left_on, right_on=right_on).drop(right_on, axis=1)\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: \"unidentified\" if x == None else x)\n",
    "    df[\"label\"] = df[\"label\"].fillna(\"unidentified\")\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: \"solo staker\" if x.endswith(\".eth\") else x.lower())\n",
    "    largest = df.groupby(\"label\")[\"validator\"].sum().reset_index().sort_values(\"validator\", ascending=False)[\"label\"].tolist()[0:nlargest]\n",
    "    if \"solo staker\" not in largest:\n",
    "        largest.append(\"solo staker\")\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: x if x in largest else \"other\")\n",
    "    if \"other\" not in largest:\n",
    "        largest.append(\"other\")\n",
    "    return df, largest\n",
    "\n",
    "def add_info_to_df(df):\n",
    "    df = add_slot_in_epoch(df)\n",
    "    #df.drop([\"failed\", \"missed\"], axis=1, inplace=True)\n",
    "    #df.drop_duplicates(inplace=True)\n",
    "    df, largest = merge_labels(df, labels)\n",
    "    return df, largest\n",
    "\n",
    "def check_duties(epoch):\n",
    "    epoch_start = epoch * 32\n",
    "    dfs = []\n",
    "    for i in range(epoch_start, epoch_start + 32):\n",
    "        df = pd.read_parquet(f\"{DATA}/duties/{i}.parquet\").drop_duplicates()\n",
    "        df['slot'] = i\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "def handle_labels(_df, nlargest=15):\n",
    "    df = _df.copy()\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: \"unidentified\" if x == None else x)\n",
    "    df[\"label\"] = df[\"label\"].fillna(\"unidentified\")\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: \"solo staker\" if x.endswith(\".eth\") else x.lower())\n",
    "    largest = df.groupby(\"label\")[\"validator\"].sum().reset_index().sort_values(\"validator\", ascending=False)[\"label\"].tolist()[0:nlargest]\n",
    "    if  \"solo staker\" not in largest:\n",
    "        largest.append(\"solo staker\")\n",
    "    df[\"label\"] = df[\"label\"].apply(lambda x: x if x in largest else \"other\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_totals(epoch, nlargest=15):\n",
    "    duties = check_duties(epoch)\n",
    "    duties = pd.merge(duties, labels, how=\"left\", left_on=\"validator\", right_on=\"validator_id\").drop(\"validator_id\", axis=1)\n",
    "    duties = handle_labels(duties, nlargest)\n",
    "    totals = duties.groupby(\"label\")[\"validator\"].nunique().reset_index().sort_values(\"validator\")\n",
    "    return totals\n",
    "\n",
    "def get_all_misses_and_totals(df, nlargest=15):\n",
    "    misses = df.groupby(\"label\")[\"validator\"].nunique().reset_index().sort_values(\"validator\")\n",
    "    totals = get_totals(df.epoch.max())\n",
    "    return totals, misses\n",
    "\n",
    "def get_offline_validator_count(df):\n",
    "    print(\"offline validators\")\n",
    "    missed = df.groupby([\"validator\", \"label\"])[\"slot\"].nunique().reset_index().sort_values(\"slot\")\n",
    "    mi = missed[missed[\"slot\"] > 1].reset_index(drop=True)\n",
    "    print(f\"offline for {mi.slot.sum()} slots, {mi.slot.sum() // 32} epochs\")\n",
    "    mi = mi[mi[\"slot\"] == mi.slot.max()].groupby(\"label\")[\"validator\"].nunique().reset_index().sort_values(\"validator\")\n",
    "    print(mi.to_markdown())\n",
    "\n",
    "def add_date_to_df(df):\n",
    "    BASE_TIMESTAMP = 1606824023\n",
    "    SLOT_DURATION = 12\n",
    "    timestamps = BASE_TIMESTAMP + pd.Series(df[\"slot\"]) * SLOT_DURATION\n",
    "    dt_objects = pd.to_datetime(timestamps, unit='s')\n",
    "    formatted_times = dt_objects.dt.strftime(\"%Y-%m-%d %H:00\") \n",
    "    df[\"date\"] = formatted_times\n",
    "    return df\n",
    "\n",
    "def add_day_to_df(df):\n",
    "    BASE_TIMESTAMP = 1606824023\n",
    "    SLOT_DURATION = 12\n",
    "    timestamps = BASE_TIMESTAMP + pd.Series(df[\"slot\"]) * SLOT_DURATION\n",
    "    dt_objects = pd.to_datetime(timestamps, unit='s')\n",
    "    formatted_times = dt_objects.dt.strftime(\"%Y-%m-%d\") \n",
    "    df[\"date\"] = formatted_times\n",
    "    return df\n",
    "\n",
    "def combine_failed_and_missed_columns(df):\n",
    "    conditions = [\n",
    "        (df['failed'] == 1),\n",
    "        (df['missed'] == 1)\n",
    "    ]\n",
    "\n",
    "    choices = ['failed', 'missed']\n",
    "    df['status'] = np.select(conditions, choices, default='success')\n",
    "    #df.drop([\"missed\", \"failed\"], axis=1, inplace=True)\n",
    "    df.replace(\"failed\", f\"wrong {WHAT} vote\", inplace=True)\n",
    "    df.replace(\"missed\", f\"missed/offline\", inplace=True)\n",
    "    return df\n",
    "\n",
    "def get_slot_per_epoch_totals_dff(gdf_grouped):\n",
    "    dff = dict()\n",
    "    for i in gdf_grouped.slot_in_epoch.unique():\n",
    "        _dff = gdf_grouped[gdf_grouped[\"slot_in_epoch\"] == i]\n",
    "        dff[i] = _dff.validator.sum()\n",
    "    return dff\n",
    "\n",
    "def get_time_in_curr_slot(ts, slot):\n",
    "    return (ts - (1654824023000 + (slot-1-4e6)*12000) - 12000) / 1000 \n",
    "\n",
    "def load_timing_data(df, overwrite=False, rounding=1):\n",
    "    try:\n",
    "        if overwrite == True:\n",
    "            raise\n",
    "        block_timing = pd.read_parquet(f\"{DATA}/{TMP}/block_timings.parquet\")\n",
    "        block_timing[\"time_in_slot\"] = block_timing.apply(lambda x: get_time_in_curr_slot(x[\"timestamp_ms\"], x[\"slot\"]), axis=1)\n",
    "        block_timing.dropna(subset=\"time_in_slot\", inplace=True)\n",
    "        block_timing[\"time_in_slot\"] = block_timing[\"time_in_slot\"].astype(float)\n",
    "        block_timing[\"time_in_slot\"] = block_timing[\"time_in_slot\"].round(rounding)     \n",
    "        print(\"timing_data read locally\")\n",
    "        return block_timing[[\"slot\", \"time_in_slot\"]]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        block_timing = pandas_gbq.read_gbq(f\"\"\"\n",
    "            SELECT distinct A.slot, A.block_hash, min(timestamp_ms) timestamp_ms , 1 as mevboost\n",
    "              FROM (\n",
    "                      SELECT slot, block_hash \n",
    "                      FROM `ethereum-data-nero.eth.mevboost_db` \n",
    "                      WHERE date > \"2024-05-25\"\n",
    "                  ) A LEFT JOIN (\n",
    "                      SELECT block_hash, slot, timestamp_ms \n",
    "                      FROM `ethereum-data-nero.eth.mevboost_all_bids` \n",
    "                      UNION ALL\n",
    "                      SELECT block_hash, slot, timestamp_ms fROM `ethereum-data-nero.eth.mevboost_all_bids_archive_0`\n",
    "                      UNION ALL\n",
    "                      SELECT block_hash, slot, timestamp_ms fROM `ethereum-data-nero.eth.mevboost_all_bids_archive_1`\n",
    "                      UNION ALL\n",
    "                      SELECT block_hash, slot, timestamp_ms fROM `ethereum-data-nero.eth.mevboost_all_bids_archive_4`\n",
    "\n",
    "          ) B on A.slot = B.slot and A.block_hash = B.block_hash\n",
    "          where A.slot >= {df.slot.min()}\n",
    "          group by slot, block_hash\n",
    "        \"\"\")\n",
    "        block_timing[\"time_in_slot\"] = block_timing.apply(lambda x: get_time_in_curr_slot(x[\"timestamp_ms\"], x[\"slot\"]), axis=1)\n",
    "        block_timing.dropna(subset=\"time_in_slot\", inplace=True)\n",
    "        block_timing[\"time_in_slot\"] = block_timing[\"time_in_slot\"].astype(float)\n",
    "        block_timing[\"time_in_slot\"] = block_timing[\"time_in_slot\"].round(rounding)\n",
    "        block_timing.to_parquet(f\"{DATA}/{TMP}/block_timings.parquet\", index=False)        \n",
    "        return block_timing[[\"slot\", \"time_in_slot\"]]\n",
    "    \n",
    "def prepare_failed_with_size(_df, only_failed=True, overwrite=False):\n",
    "    if only_failed:\n",
    "        df = _df[_df[\"failed\"] == 1].copy()\n",
    "    else:\n",
    "        df = _df.copy()\n",
    "    size = get_block_sizes(df, overwrite)\n",
    "    size[\"size_compressed_total\"] = size[\"size_compressed\"] + size[\"blobs\"]   \n",
    "    df = pd.merge(df, size[[\"slot\", \"size\", \"size_compressed\", \"size_compressed_total\", \"blobs\"]], how=\"left\", left_on=\"slot\", right_on=\"slot\")\n",
    "    aggr = {\n",
    "        \"size\": \"mean\",\n",
    "        \"size_compressed\": \"mean\",\n",
    "        \"validator\": \"nunique\",\n",
    "        \"size_compressed_total\": \"mean\",\n",
    "        \"blobs\": \"mean\"\n",
    "    }\n",
    "    df = df.groupby(\"slot\")[[\"size\", \"size_compressed\", \"validator\", \"size_compressed_total\", \"blobs\"]].agg(aggr).reset_index()\n",
    "    return df\n",
    "\n",
    "def remove_last_day(_df):\n",
    "    df = _df.copy()\n",
    "    df = add_day_to_df(df)\n",
    "    return df[df[\"date\"] != df.date.max()]\n",
    "\n",
    "def get_share(ee):\n",
    "    return ee.groupby(\"time_in_slot\")[\"slot\"].nunique().reset_index().sort_values(\"slot\", ascending=False).set_index(\"time_in_slot\").to_dict()[\"slot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_df()\n",
    "print(len(df))\n",
    "df = remove_last_day(df)\n",
    "print(len(df))\n",
    "df = df[df[\"epoch\"] > df.epoch.max() - DAYS*225]\n",
    "print(len(df))\n",
    "print(f\"having {df.epoch.nunique()} epochs, {df.epoch.nunique()//225} days\")\n",
    "\n",
    "labels = get_labels(overwrite=OVERWRITE)\n",
    "\n",
    "clients_final = get_clients(overwrite=OVERWRITE)\n",
    "\n",
    "df, largest = add_info_to_df(df)\n",
    "\n",
    "get_offline_validator_count(df)\n",
    "\n",
    "df = add_date_to_df(df)\n",
    "\n",
    "block_timing = load_timing_data(df, overwrite=OVERWRITE)\n",
    "\n",
    "totals, misses = get_all_misses_and_totals(df, nlargest=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaps\n",
    "print(\"gaps: \", str(set(range(df.epoch.min(), df.epoch.max()+1)) - set(df.epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862dd43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"first/last slot ind data: \", f\"{df.slot.min()}/{df.slot.max()}\")\n",
    "print(\"first/last slot ind data: \", f\"{slot_to_hour(df.slot.min())}/{slot_to_hour(df.slot.max())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffba26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "legit = set(check_duties(df.epoch.min())[\"validator\"].tolist()).intersection(set(check_duties(df.epoch.max())[\"validator\"].tolist()))\n",
    "len(legit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88644905",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df =  df[df[\"epoch\"] > df.epoch.max() - 3*225].copy()\n",
    "_df = _df[_df.validator.isin(legit)]\n",
    "_df = _df.groupby(\"validator\")[\"epoch\"].nunique().reset_index()\n",
    "_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c326bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals, misses = get_all_misses_and_totals(df, nlargest=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no misses\n",
    "m = set(_df[\"validator\"])\n",
    "m = [i for i in legit if i not in m]\n",
    "len(m), len(m)-len(legit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61903984",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_misses = labels[labels[\"validator_id\"].isin(m)]\n",
    "no_misses.columns = [\"validator\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51686021",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_misses = handle_labels(no_misses, 30)\n",
    "no_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_misses.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e3dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_misses = no_misses.groupby(\"label\")[\"validator\"].nunique().reset_index().sort_values(\"validator\")\n",
    "no_misses[\"per\"] = no_misses[\"validator\"]/no_misses.validator.sum()*100\n",
    "no_misses[\"label\"] = no_misses[\"label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afe79f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5a4221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totals[\"per\"] = totals[\"validator\"]/totals.validator.sum()*100\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bedde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_miss_total = pd.merge(totals[[\"label\", \"per\"]], no_misses[[\"label\", \"per\"]], how=\"inner\", left_on=\"label\", right_on=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_miss_total.sort_values(\"per_x\", ascending=False, inplace=True)\n",
    "no_miss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca79a6",
   "metadata": {},
   "source": [
    "### Worst validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3c1d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def head_votes_over_validator_ids(df):\n",
    "    _df = df[df.validator.isin(legit)].copy()\n",
    "    _df = _df.groupby(\"validator\")[\"epoch\"].nunique().reset_index()\n",
    "    _df[\"valr\"] = _df[\"validator\"] // 10000 * 10000\n",
    "    dd = _df.groupby(\"valr\")[\"epoch\"].sum().reset_index()\n",
    "    dd[\"epoch\"] = dd[\"epoch\"] / df.epoch.nunique()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "            x=dd['valr'],\n",
    "            y=dd['epoch'],\n",
    "            name='Share in Top Performing Validators (%)',\n",
    "            marker_color=COLORS[0]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes Over Validator IDs <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        xaxis_title=\"validator id\",\n",
    "        yaxis_title=f'missed/failed {WHAT} votes',\n",
    "        barmode='group',\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=\"Ubuntu Mono\", size=FONTSIZE),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray', tickformat=\",d\"),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray',),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = head_votes_over_validator_ids(df)\n",
    "fig.write_image(f\"{IMAGE}/{WHAT}_votes_over_validator_ids.png\")\n",
    "if SHOW:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3f50a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_votes_over_offline_validator_ids(df):\n",
    "    _df = df[df.validator.isin(legit)].copy()\n",
    "    _df = _df.groupby(\"validator\")[\"epoch\"].nunique().reset_index()\n",
    "    offline = _df[_df[\"epoch\"] == _df.epoch.max()]\n",
    "    offline[\"valr\"] = offline[\"validator\"] // 10000 * 10000\n",
    "    dd = offline.groupby(\"valr\")[\"validator\"].count().reset_index()\n",
    "    #dd[\"epoch\"] = dd[\"epoch\"] / df.epoch.nunique()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "            x=dd['valr'],\n",
    "            y=dd['validator'],\n",
    "            name='Share in Top Performing Validators (%)',\n",
    "            marker_color=COLORS[0]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Offline Validators Over Validator IDs <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        xaxis_title=\"Validator ID\",\n",
    "        yaxis_title=f'missed/failed {WHAT} votes',\n",
    "        barmode='group',\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=\"Ubuntu Mono\", size=FONTSIZE),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray', tickformat=\",d\"),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray',),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = head_votes_over_offline_validator_ids(df)\n",
    "fig.write_image(f\"{IMAGE}/{WHAT}_votes_over_offline_validator_ids.png\")\n",
    "if SHOW:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab294220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_votes_over_bad_validator_ids(df):\n",
    "    _df = df[df.validator.isin(legit)].copy()\n",
    "    _df = _df.groupby(\"validator\")[\"epoch\"].nunique().reset_index()\n",
    "    noffline = _df[_df[\"epoch\"] != _df.epoch.max()]\n",
    "    noffline = noffline[noffline[\"epoch\"] > noffline.epoch.mean()]\n",
    "    noffline[\"valr\"] = noffline[\"validator\"] // 10000 * 10000\n",
    "    dd = noffline.groupby(\"valr\")[\"validator\"].count().reset_index()\n",
    "    #dd[\"epoch\"] = dd[\"epoch\"] / df.epoch.nunique()\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Bar(\n",
    "            x=dd['valr'],\n",
    "            y=dd['validator'],\n",
    "            name='Share in Top Performing Validators (%)',\n",
    "            marker_color=COLORS[0]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Bad Validators Over Validator IDs <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        xaxis_title=\"validator id\",\n",
    "        yaxis_title=f'missed/failed {WHAT} votes',\n",
    "        barmode='group',\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=\"Ubuntu Mono\", size=FONTSIZE),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray', tickformat=\",d\"),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray',),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        )\n",
    "    fig.add_annotation(\n",
    "            text=\"* bad validators miss more than avg. but are not offline\",\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            x=0.95,\n",
    "            y=1,\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                family=FONTFAMILY,\n",
    "                size=FONTSIZE-2,\n",
    "                color=\"black\"\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = head_votes_over_bad_validator_ids(df)\n",
    "fig.write_image(f\"{IMAGE}/{WHAT}_votes_over_bad_validator_ids.png\")\n",
    "if SHOW:\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58330c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_votes_best(df):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['label'],\n",
    "        y=df['per_x'],\n",
    "        name='Total Share (%)',\n",
    "        marker_color=COLORS[0]\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['label'],\n",
    "        y=df['per_y'],\n",
    "        name='Share in Top Performing Validators (%)',\n",
    "        marker_color=COLORS[1]\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Total Validator Share vs. Share in Top Performing Validators',\n",
    "        xaxis_title=None,\n",
    "        yaxis_title='%',\n",
    "        barmode='group',\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=\"Ubuntu Mono\", size=FONTSIZE),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray', range=[0, 100])\n",
    "    )\n",
    "    return fig\n",
    "#\n",
    "#fig = performance_votes_best(no_miss_total)\n",
    "#fig.write_image(f\"{IMAGE}/performer_vs_total.png\")\n",
    "#if SHOW:\n",
    "#    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33449bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no_miss_total\n",
    "#no_miss_total2 = pd.merge(totals[[\"label\", \"validator\"]], no_misses[[\"label\", \"validator\"]], how=\"inner\", left_on=\"label\", right_on=\"label\")\n",
    "#no_miss_total2[\"per\"] = no_miss_total2[\"validator_y\"] / no_miss_total2[\"validator_x\"] * 100\n",
    "#no_miss_total2.sort_values(\"per\", ascending=False, inplace=True)\n",
    "#no_miss_total2\n",
    "\n",
    "def performance_votes_best2(df):\n",
    "    start_color = '#377eb8'\n",
    "    end_color = '#8cb6fa'\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_gradient\", [start_color, end_color])\n",
    "    gradient = [mcolors.rgb2hex(cmap(i / 19)) for i in range(20)]\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df['label'],\n",
    "        y=df['per'],\n",
    "        name='Total Share (%)',\n",
    "        marker_color=gradient\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Total Validator Share vs. Share in Top Performing Validators',\n",
    "        xaxis_title=None,\n",
    "        yaxis_title='%',\n",
    "        barmode='group',\n",
    "        plot_bgcolor='white',\n",
    "        font=dict(family=\"Ubuntu Mono\", size=FONTSIZE),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        xaxis=dict(showgrid=True, gridcolor='lightgray'),\n",
    "        yaxis=dict(showgrid=True, gridcolor='lightgray',)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "#fig = performance_votes_best2(no_miss_total2)\n",
    "#fig.write_image(f\"{IMAGE}/performer_share_{WHAT}.png\")\n",
    "#if SHOW:\n",
    "#    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(f\"{DATA}/failed_{WHAT}/\")\n",
    "\n",
    "duties_files = os.listdir(f\"{DATA}/duties/\")\n",
    "duties_files = set([f\"{int(i.split('.')[0])//32}.parquet\" for i in duties_files])\n",
    "files = sorted([f  for f in files if f in duties_files], key=lambda x: int(x.split(\".\")[0]))\n",
    "print(f\"slots in files: {len(files)*32} | {len(files)*32//7200} days of data\")\n",
    "print(f\"First file:\\n{files[0]}\")\n",
    "print(f\"Last file:\\n{files[-1]}\")\n",
    "print(f'{labels.dropna()[labels.dropna()[\"label\"].str.endswith(\".eth\")].validator_id.nunique()} unique solo stakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac9318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_votes_over_slot_in_eooch(_df):\n",
    "    df = _df.copy()\n",
    "    df.drop([\"failed\", \"missed\"], axis=1, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df = df.groupby([\"slot_in_epoch\", \"label\"])[\"validator\"].count().reset_index().sort_values(\"slot_in_epoch\")\n",
    "    df = df.reset_index(drop=True)\n",
    "    df[\"validator\"] = df[\"validator\"] / (_df.slot.nunique()/32)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, label in enumerate(largest):\n",
    "        df_label = df[df['label'] == label]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_label['slot_in_epoch'],\n",
    "            y=df_label['validator'],\n",
    "            name=label,\n",
    "            marker_color=COLORS2[ix]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Slot In Epoch <span style=\"font-size: 16px;\">({slot_to_day(_df.slot.min())} - {slot_to_day(_df.slot.max())})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"slot in epoch\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes per slot\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT*1.25,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = missed_votes_over_slot_in_eooch(df)\n",
    "fig.write_image(f\"{IMAGE}/missed_{WHAT}_votes_over_slot.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa610b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfm = pd.merge(misses, totals, how=\"left\", left_on=\"label\", right_on=\"label\")\n",
    "#dfm[\"validator_x\"] = dfm[\"validator_x\"] / dfm[\"validator_x\"].sum() *100\n",
    "#dfm[\"validator_y\"] = dfm[\"validator_y\"] / dfm[\"validator_y\"].sum() *100\n",
    "#dfm = dfm.iloc[::-1]\n",
    "\n",
    "#fig = go.Figure()\n",
    "#\n",
    "#colors = [\n",
    "#    '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628', '#e41a1c', \n",
    "#    '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99', '#cab2d6',\n",
    "#    '#1f78b4', '#33a02c', '#ff7f7f'\n",
    "#]\n",
    "#\n",
    "## Create subplots: use 'domain' type for pie-like plots\n",
    "#fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "#\n",
    "## Add line trace for expected misses\n",
    "#fig.add_trace(\n",
    "#    go.Scatter(x=dfm['label'], y=dfm['validator_y'], name='Validator Marketshare', mode='lines+markers', \n",
    "#               line=dict(color='darkblue'), marker=dict(color='darkblue')),\n",
    "#)\n",
    "#\n",
    "#\n",
    "## Add bar trace for actual misses\n",
    "#fig.add_trace(\n",
    "#    go.Bar(x=dfm['label'], y=dfm['validator_x'], name='Missed Source Marketshare',\n",
    "#    marker_color=colors[:len(dfm['label'])]\n",
    "#          )\n",
    "#)\n",
    "#\n",
    "#fig.update_layout(\n",
    "#    title_text=f'Comparison of Expected and Actual Misses per Validator <span style=\"font-size: 14px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "#    legend=dict(x=0.9, y=0.98),\n",
    "#    barmode='group',\n",
    "#    legend_traceorder=\"normal\",\n",
    "#    xaxis=dict(\n",
    "#        tickmode='linear',\n",
    "#        showgrid=True,\n",
    "#        gridcolor='lightgrey',\n",
    "#        title=None\n",
    "#    ),\n",
    "#    yaxis=dict(\n",
    "#        title=\"%\",\n",
    "#        showgrid=True,\n",
    "#        gridcolor='lightgrey',\n",
    "#        #type=\"log\"\n",
    "#    ),\n",
    "#    height=550,\n",
    "#    width=1200,\n",
    "#    font=dict(\n",
    "#        family=\"Ubuntu Mono\",\n",
    "#        size=14,\n",
    "#        color=\"black\"\n",
    "#    ),\n",
    "#    plot_bgcolor = \"#FFFFFF\"\n",
    "#)\n",
    "#\n",
    "## Show plot\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10869013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfm[\"delta\"] = dfm[\"validator_x\"] - dfm[\"validator_y\"]\n",
    "##dfm[\"delta_per\"] = dfm[\"delta\"] / dfm[\"validator_x\"] * 100\n",
    "#dfm.columns = [\"Validator\", \"Share in missed source votes (%)\", \"Share in total validator market (%)\", \"Delta\"]\n",
    "#\n",
    "#print(dfm.iloc[::-1].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0473bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delta_chart(_df):\n",
    "    df = _df.copy()\n",
    "    df = df.drop([\"failed\", \"missed\"], axis=1)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    missed = df.groupby([\"validator\", \"label\"])[\"slot\"].nunique().reset_index().sort_values(\"slot\")\n",
    "    mi = missed[missed[\"slot\"] > 1].reset_index(drop=True)\n",
    "    mis = pd.merge(missed.groupby(\"label\")[\"slot\"].sum().reset_index().sort_values(\"slot\"), totals, how=\"left\", left_on = \"label\", right_on = \"label\")\n",
    "    mis[\"validator\"] = mis[\"validator\"] * df.epoch.nunique()\n",
    "    mis[\"actual_percentage\"] = mis[\"slot\"] / mis[\"validator\"]*100\n",
    "    mis.sort_values(\"actual_percentage\", ascending=False).reset_index(drop=True)\n",
    "    mis[\"expected_percentage\"] = (mis[\"slot\"].sum()/mis[\"validator\"].sum())*100\n",
    "    mis[\"greater\"] = mis[\"actual_percentage\"] > mis[\"expected_percentage\"]\n",
    "    mis = mis[[\"label\", \"actual_percentage\", \"expected_percentage\", \"greater\"]]\n",
    "    mis[\"delta\"] = mis[\"actual_percentage\"] - mis[\"expected_percentage\"]\n",
    "    colors = mis[\"delta\"].apply(lambda x: COLORS[0] if x > 0 else COLORS[1])\n",
    "    mis.sort_values(\"delta\", inplace=True)    \n",
    "    mis.dropna(subset=\"delta\", inplace=True)\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adding the bars\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=mis[\"label\"],\n",
    "        y=mis[\"delta\"],\n",
    "        marker_color=mis[\"delta\"].apply(lambda x: COLORS[0] if x > 0 else COLORS[1]),\n",
    "        name='Performance Delta comparing `Actual` with `Expected`'\n",
    "    ))\n",
    "\n",
    "    # Adding the expected percentage line\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=mis[\"label\"],\n",
    "        y=[0] * len(mis),\n",
    "        mode='lines',\n",
    "        line=dict(color='black', dash='dash', width=3),\n",
    "        name='Expected Missed Source Votes based on Market Share'\n",
    "    ))\n",
    "\n",
    "    # Updating layout\n",
    "    fig.update_layout(\n",
    "        title_text=f'Comparison of Expected and Actual Misses per Validator <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        legend=dict(x=0, y=1),\n",
    "        barmode='group',\n",
    "        legend_traceorder=\"reversed\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=None\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"%\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            #type=\"log\"\n",
    "             range=[-3, 3.5]\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT*1.1,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = create_delta_chart(df)\n",
    "fig.write_image(f\"{IMAGE}/delta_missed_{WHAT}_votes.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0840d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_votes_over_time(_df):\n",
    "    df = _df.copy()\n",
    "    df = df.drop([\"failed\", \"missed\"], axis=1)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df[\"date\"] = df[\"date\"].str.split(\" \").str[0]\n",
    "    df = df.groupby([\"date\", \"label\"])[\"validator\"].count().reset_index()\n",
    "    df[\"validator\"] = df[\"validator\"] / (60*60*24/12)    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add a bar for each label\n",
    "    for ix, label in enumerate(largest):\n",
    "        df_label = df[df['label'] == label]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_label['date'],\n",
    "            y=df_label['validator'],\n",
    "            name=label,\n",
    "            marker_color=COLORS2[ix % len(COLORS2)]\n",
    "            \n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Average Number of Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes per Slot',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=None\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes per slot\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT*1.25,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = missed_votes_over_time(df)\n",
    "fig.write_image(f\"{IMAGE}/missed_{WHAT}_votes_over_date.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_reorged_over_slots(_df):\n",
    "    df = _df.copy()\n",
    "    df = combine_failed_and_missed_columns(df)\n",
    "    df = df.groupby([\"slot_in_epoch\", \"status\"])[\"validator\"].count().reset_index().sort_values(\"slot_in_epoch\")\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df.replace(\"failed\", f\"wrong {WHAT} vote\", inplace=True)\n",
    "    df.replace(\"missed\", f\"missed/offline\", inplace=True)\n",
    "    df[\"validator\"] = df[\"validator\"] / (_df.slot.nunique()/32)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, status in enumerate(df.status.unique()):\n",
    "        df_status = df[df['status'] == status]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_status['slot_in_epoch'],\n",
    "            y=df_status['validator'],\n",
    "            name=status,\n",
    "            marker_color=COLORS[ix]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Slot In Epoch <span style=\"font-size: 16px;\">({slot_to_day(_df.slot.min())} - {slot_to_day(_df.slot.max())})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        legend=dict(x=0.81, y=1),\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"slot in epoch\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = missed_reorged_over_slots(df)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f983d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def failed_misse_percentage_over_slot(_df):\n",
    "    df = _df.copy()\n",
    "    min_max_slots = (df.slot.min(), df.slot.max())\n",
    "    dff = get_slot_per_epoch_totals_dff(\n",
    "        combine_failed_and_missed_columns(df).groupby(\n",
    "            [\"slot_in_epoch\", \"status\"]\n",
    "        )[\"validator\"].count().reset_index().sort_values(\"slot_in_epoch\")\n",
    "    ) \n",
    "    df = df.groupby([\"slot_in_epoch\", \"status\"])[\"validator\"].count().reset_index().sort_values(\"slot_in_epoch\")\n",
    "    df[\"validator\"] = df.apply(lambda x: x[\"validator\"]/dff[x[\"slot_in_epoch\"]] * 100, axis=1)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    colors = [COLORS[1]] + [COLORS[0]]\n",
    "    for ix, status in enumerate([\"missed/offline\", f\"wrong {WHAT} vote\"][::-1]):\n",
    "        df_status = df[df['status'] == status]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_status['slot_in_epoch'],\n",
    "            y=df_status['validator'],\n",
    "            name=status,\n",
    "            marker_color=colors[ix]\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Slot In Epoch <span style=\"font-size: 16px;\">({slot_to_day(min_max_slots[0])} - {slot_to_day(min_max_slots[1])})</span>',\n",
    "        barmode='stack',\n",
    "        legend=dict(x=0.79, y=0.02),\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"slot in epoch\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"%\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = failed_misse_percentage_over_slot(df)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes_per.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_over_clients_over_time(_df, clients_final):\n",
    "    df = _df.copy()\n",
    "    df = pd.merge(df, clients_final, how=\"left\", left_on=\"validator\", right_on=\"validator_id\")\n",
    "    \n",
    "    min_max_slots = (df.slot.min(), df.slot.max())\n",
    "    df[\"cl_client\"] = df[\"cl_client\"].fillna(\"Unknown\")\n",
    "    BASE_TIMESTAMP = 1606824023\n",
    "    SLOT_DURATION = 12\n",
    "    timestamps = BASE_TIMESTAMP + pd.Series(df[\"slot\"]) * SLOT_DURATION\n",
    "    dt_objects = pd.to_datetime(timestamps, unit='s')\n",
    "    df[\"hour\"] = dt_objects.dt.strftime(\"%Y-%m-%d\")\n",
    "    #df[\"date\"] = df[\"date\"].str.split(\" \").str[0]\n",
    "    df = df.groupby([\"cl_client\", \"hour\"])[\"validator\"].count().reset_index().sort_values(\"validator\", ascending=False)\n",
    "    df[\"validator\"] = df[\"validator\"] / (60*60*24/12)   \n",
    "    #df.set_index(\"cl_client\", inplace=True)\n",
    "    #df = df.loc[[\"Lighthouse\",  'Prysm', 'Teku', 'Nimbus', 'Lodestar', \"Unknown\"]]\n",
    "    #df.reset_index(inplace=True)\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add a bar for each label\n",
    "    for ix, cl_client in enumerate([\"Lighthouse\",  'Prysm', 'Teku', 'Nimbus', 'Lodestar', \"Unknown\"]):\n",
    "        df_cl_client = df[df['cl_client'] == cl_client]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_cl_client['hour'],\n",
    "            y=df_cl_client['validator'],\n",
    "            name=cl_client,\n",
    "            marker_color=COLORS2[ix % len(COLORS2)]\n",
    "        ))\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes per CL Client <span style=\"font-size: 16px;\">({slot_to_day(min_max_slots[0])} - {slot_to_day(min_max_slots[1])})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=None\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes per slot\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=500,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = missed_over_clients_over_time(df, clients_final)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes_over_clclient.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6205b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_over_clients_over_slots_in_epoch(df, clients_final):\n",
    "    min_max_slots = (df.slot.min(), df.slot.max())\n",
    "    ee = pd.merge(df, clients_final, how=\"left\", left_on=\"validator\", right_on=\"validator_id\")\n",
    "    ee[\"cl_client\"] = ee[\"cl_client\"].fillna(\"Unknown\")\n",
    "    ee[\"slot_in_epoch\"] = ee[\"slot\"] % 32\n",
    "    \n",
    "    dfg0 = ee.groupby([\"cl_client\", \"slot_in_epoch\"])[\"validator\"].count().reset_index().sort_values(\"validator\", ascending=False)\n",
    "    dfg0 = dfg0.reset_index(drop=True)\n",
    "    dfg0[\"validator\"] = dfg0[\"validator\"] / (df.slot.nunique()/32)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add a bar for each label\n",
    "    for ix, label in enumerate(ee.groupby(\"cl_client\")[\"validator\"].nunique().reset_index().sort_values(\"validator\", ascending=False)[\"cl_client\"].tolist()):\n",
    "        df_label = dfg0[dfg0['cl_client'] == label]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=df_label['slot_in_epoch'],\n",
    "            y=df_label['validator'],\n",
    "            name=label,\n",
    "            marker_color=COLORS2[ix % len(COLORS2)]\n",
    "        ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Slot In Epoch <span style=\"font-size: 16px;\">({slot_to_day(min_max_slots[0])} - {slot_to_day(min_max_slots[1])})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=f\"slot in epoch\",\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "fig = missed_over_clients_over_slots_in_epoch(df, clients_final)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes_over_clclient_over_slot.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d83729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_failed_with_timing_in_slot(_df):\n",
    "    fontfamily = \"Ubuntu Mono\"\n",
    "    df = _df.copy()\n",
    "    df = combine_failed_and_missed_columns(df)\n",
    "    df = pd.merge(df, block_timing, how=\"left\", left_on=\"slot\", right_on=\"slot\").dropna()\n",
    "    df[\"time_in_slot\"] = df[\"time_in_slot\"].apply(lambda x: x if x < 2 else 2)\n",
    "    \n",
    "    print(f\"having {df.epoch.nunique()} epochs, {df.epoch.nunique()//225} days\")\n",
    "    share = get_share(df)    \n",
    "    \n",
    "    ee = df[[\"validator\" ,\"time_in_slot\", \"status\"]]\n",
    "    \n",
    "\n",
    "    ee = ee.groupby([\"time_in_slot\", \"status\"])[\"validator\"].count().reset_index().sort_values(\"time_in_slot\", ascending=False)\n",
    "    ee[\"time_in_slot_per\"] = ee[\"time_in_slot\"].apply(lambda x: share[x])\n",
    "    ee[\"validator\"] = ee[\"validator\"] / ee[\"time_in_slot_per\"]\n",
    "    rr = set(ee[ee[\"time_in_slot_per\"] >= 25].time_in_slot.tolist())\n",
    "    ee = ee[ee[\"time_in_slot\"].isin(rr)]\n",
    "    ee = ee[ee[\"time_in_slot\"] >= 0]\n",
    "    ee = ee[ee[\"time_in_slot\"] <= 10]\n",
    "    ee.replace(\"failed\", f\"wrong {WHAT} vote\", inplace=True)\n",
    "    ee.replace(\"missed\", f\"missed/offline\", inplace=True)\n",
    "    ee.sort_values([\"time_in_slot\", \"status\"], ascending=[False, True], inplace=True)\n",
    "    \n",
    "    fig = px.bar(ee, x='time_in_slot', y='validator', color='status', title='Validator Status by Time in Slot',\n",
    "                 labels={'time_in_slot': 'Time in Slot', 'validator': 'Validator', 'status': 'Status'},\n",
    "                 barmode='stack')\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Seconds in Slot <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        legend=dict(x=0, y=0.98, title=None),\n",
    "\n",
    "        xaxis=dict(\n",
    "            #tickmode='linear',\n",
    "            #range=[0, 2],\n",
    "             tickmode = 'array',\n",
    "            tickvals = list(np.array(list(range(0,20)))/10) + [2],\n",
    "            ticktext = list(np.array(list(range(0,20)))/10) + [\"2+\"],\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"seconds in slot (builder bid received)\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes per slot\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    share = {i: share[i] for i in share.keys() if i >= 0}\n",
    "    share = {i: share[i] for i in share.keys() if i in rr}\n",
    "    for i, size in enumerate(share.keys()):\n",
    "        if (size*10+1) % 2 == 0:\n",
    "            delta = 0.02\n",
    "        else:\n",
    "            delta = -0.02\n",
    "        fig.add_annotation(\n",
    "            text=f\"n={share[size]:,}\",\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            x=size,\n",
    "            y=0.05+delta,\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                family=fontfamily,\n",
    "                size=FONTSIZE-4,\n",
    "                color=\"black\"\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = missed_failed_with_timing_in_slot(df)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes_over_timing.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce77a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_failed_with_timing_in_slot_per(_df):\n",
    "    fontfamily = \"Ubuntu Mono\"\n",
    "    df = _df.copy()\n",
    "    df = combine_failed_and_missed_columns(df)\n",
    "    df = pd.merge(df, block_timing, how=\"left\", left_on=\"slot\", right_on=\"slot\").dropna()\n",
    "    df[\"time_in_slot\"] = df[\"time_in_slot\"].apply(lambda x: x if x < 2 else 2)\n",
    "    \n",
    "    print(f\"having {df.epoch.nunique()} epochs, {df.epoch.nunique()//225} days\")\n",
    "    share = get_share(df)   \n",
    "    \n",
    "    ee = df[[\"validator\" ,\"time_in_slot\", \"status\"]]\n",
    "    \n",
    "\n",
    "    ee = ee.groupby([\"time_in_slot\", \"status\"])[\"validator\"].count().reset_index().sort_values(\"time_in_slot\", ascending=False)\n",
    "    ee[\"time_in_slot_per\"] = ee[\"time_in_slot\"].apply(lambda x: share[x])\n",
    "    ee[\"validator\"] = ee[\"validator\"] / ee[\"time_in_slot_per\"]\n",
    "    rr = set(ee[ee[\"time_in_slot_per\"] >= 25].time_in_slot.tolist())\n",
    "    ee = ee[ee[\"time_in_slot\"].isin(rr)]\n",
    "    ee = ee[ee[\"time_in_slot\"] >= 0]\n",
    "    ee = ee[ee[\"time_in_slot\"] <= 10]\n",
    "    ee.replace(\"failed\", f\"wrong {WHAT} vote\", inplace=True)\n",
    "    ee.replace(\"missed\", f\"missed/offline\", inplace=True)\n",
    "    ee.sort_values([\"time_in_slot\", \"status\"], ascending=[False, True], inplace=True)\n",
    "\n",
    "    \n",
    "    ee[\"per\"] = ee[\"validator\"] / 32_500 * 100\n",
    "    fig = px.bar(ee, x='time_in_slot', y='per', color='status', title='Validator Status by Time in Slot',\n",
    "                 labels={'time_in_slot': 'Time in Slot', 'validator': 'Validator', 'status': 'Status'},\n",
    "                 barmode='stack')\n",
    "\n",
    "    fig.add_hline(y=100, line=dict(color='red', dash='dash'), annotation_text='all validators', \n",
    "                  annotation_position='top right')\n",
    "\n",
    "    fig.update_layout(\n",
    "        title = f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes over Seconds in Slot <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        legend=dict(x=0, y=0.98, title=None),\n",
    "\n",
    "        xaxis=dict(\n",
    "             tickmode = 'array',\n",
    "            tickvals =  list(np.array(list(range(0,20)))/10) + [2],\n",
    "            ticktext =  list(np.array(list(range(0,20)))/10) + [\"2+\"],\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"seconds in slot (builder bid received)\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=f\"missed/failed {WHAT} votes per slot (%)\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "    )\n",
    "    share = {i: share[i] for i in share.keys() if i >= 0}\n",
    "    share = {i: share[i] for i in share.keys() if i in rr}\n",
    "    for i, size in enumerate(share.keys()):\n",
    "        if (size*10+1) % 2 == 0:\n",
    "            delta = 0.02\n",
    "        else:\n",
    "            delta = -0.02\n",
    "        fig.add_annotation(\n",
    "            text=f\"n={share[size]:,}\",\n",
    "            xref=\"x\",\n",
    "            yref=\"paper\",\n",
    "            x=size,\n",
    "            y=0.05+delta,\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                family=fontfamily,\n",
    "                size=FONTSIZE-4,\n",
    "                color=\"black\"\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "fig = missed_failed_with_timing_in_slot_per(df)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_votes_over_timing_per.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_failed_per_validator_per(df):\n",
    "    _df = df.groupby(\"validator\")[\"epoch\"].nunique().reset_index().sort_values(\"epoch\")\n",
    "    _df = _df[_df[\"epoch\"] > 1]\n",
    "    distribution = sorted(_df.epoch)\n",
    "    fig = px.histogram(distribution, nbins=400, histnorm='percent')\n",
    "\n",
    "    fig.update_traces(name='Nr. of Validators', marker_color=COLORS[0])\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Missed/Failed {WHAT[0].upper() + WHAT[1:]} Votes Per Validator <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        xaxis_title='slot in epoch',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        legend_title_text='',\n",
    "        showlegend=False,\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=f\"nr. of missed/failed {WHAT} votes per validator\",\n",
    "            range=[1, max(distribution)],\n",
    "            tickvals=[1] + list(range(0, max(distribution) + 1, 250)),\n",
    "            ticktext=[1] + list(range(0, max(distribution) + 1, 250))\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"% of validators\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            type=\"log\"\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor=\"#FFFFFF\"\n",
    "    )\n",
    "    return fig\n",
    "fig = missed_failed_per_validator_per(df)\n",
    "fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_per_validator_dist_per.png\")\n",
    "if SHOW:\n",
    "    fig.show()\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2291459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = prepare_failed_with_size(df, only_failed=True, overwrite=False)\n",
    "#df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "#df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "##six = df[df[\"blobs\"] == 128*1024*6].copy()\n",
    "#hm = df[df[\"validator\"] >= 30_000].copy()\n",
    "##six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08868470",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qa = f\"\"\"\n",
    "#    SELECT DISTINCT\n",
    "#        slot, min(event_date_time) event_date_time\n",
    "#    FROM default.beacon_api_eth_v1_events_block\n",
    "#    WHERE\n",
    "#        slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "#        and slot >= {df.slot.min()}\n",
    "#    group by slot\n",
    "#    \"\"\"\n",
    "#\n",
    "#res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "#def parse_datetime(event_time_str):\n",
    "#    return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "#\n",
    "#res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "#res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "#\n",
    "#high = res[res[\"slot\"].isin((hm[\"slot\"]).tolist())]\n",
    "#low = res[~res[\"slot\"].isin((hm[\"slot\"]).tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7115649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg = pd.merge(df, res, how=\"left\", left_on=\"slot\", right_on=\"slot\")\n",
    "#gg[\"blobs\"] = gg[\"blobs\"] / (1024*128)\n",
    "#gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff19c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tt(_df):\n",
    "#    \n",
    "#    df = _df.copy()\n",
    "#    df = prepare_failed_with_size(df, only_failed=False, overwrite=True)\n",
    "#    #df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "#    df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "#    #six = df[df[\"blobs\"] == 128*1024*6].copy()\n",
    "#    hm = df[df[\"validator\"] >= 30_000].copy()\n",
    "#    \n",
    "#    def calculate_histogram(data, bins, x_range):\n",
    "#        hist, bin_edges = np.histogram(data, bins=bins, range=x_range)\n",
    "#        # Normalize to percentage\n",
    "#        total_count = np.sum(hist)\n",
    "#        hist_normalized = (hist / total_count) * 100\n",
    "#        return bin_edges, hist_normalized\n",
    "#    \n",
    "#    qa = f\"\"\"\n",
    "#        SELECT DISTINCT\n",
    "#            slot, min(event_date_time) event_date_time\n",
    "#        FROM default.beacon_api_eth_v1_events_block\n",
    "#        WHERE\n",
    "#            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "#            and slot >= {df.slot.min()}\n",
    "#        group by slot\n",
    "#        \"\"\"\n",
    "#\n",
    "#    res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "#    \n",
    "#    qa1 = f\"\"\"\n",
    "#        SELECT DISTINCT\n",
    "#            slot\n",
    "#        FROM default.canonical_beacon_block\n",
    "#        WHERE\n",
    "#            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "#            and slot >= {df.slot.min()}\n",
    "#    \"\"\"\n",
    "#    res_can = request_query(qa1, [\"slot\"])\n",
    "#    res = res[res[\"slot\"].isin(res_can.slot.unique())]\n",
    "#    return res, df\n",
    "#\n",
    "#o, _df = tt(df)\n",
    "#\n",
    "#qa = f\"\"\"\n",
    "#SELECT DISTINCT\n",
    "#    min(event_date_time) event_date_time, slot, kzg_commitment\n",
    "#FROM (SELECT DISTINCT \n",
    "#        event_date_time, \n",
    "#        slot, \n",
    "#        kzg_commitment \n",
    "#    FROM default.beacon_api_eth_v1_events_blob_sidecar\n",
    "#    WHERE\n",
    "#        event_date_time > NOW() - INTERVAL '100 day'\n",
    "#        AND meta_network_name = 'mainnet'\n",
    "#        AND slot >= {o.slot.min()}\n",
    "#    )\n",
    "#GROUP BY slot, kzg_commitment\n",
    "#\"\"\"\n",
    "#blob_times = request_query(qa, [\"event_date_time\", \"slot\", \"kzg_commitment\"])\n",
    "#\n",
    "#blob_times = blob_times.groupby(\"slot\")[\"event_date_time\"].max().reset_index()\n",
    "#blob_times.columns = [\"slot\", \"last_blob_timing\"]\n",
    "#\n",
    "#res = pd.merge(o, blob_times, how=\"left\", left_on=\"slot\", right_on=\"slot\")\n",
    "#res = res.dropna()\n",
    "#\n",
    "#def parse_datetime(event_time_str):\n",
    "#    return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "#\n",
    "#res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "#res['last_blob_timing_unix'] = res['last_blob_timing'].apply(lambda x: parse_datetime(x))\n",
    "#res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "#res[\"seconds_in_slot2\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"last_blob_timing_unix\"], x[\"slot\"]), axis=1)\n",
    "#\n",
    "#gg = pd.merge(_df, res, left_on=\"slot\", right_on=\"slot\")\n",
    "#gg[\"blobs\"] = gg[\"blobs\"] / (1024*128)\n",
    "#gg[\"block_earlier\"] = gg[\"seconds_in_slot\"] < gg[\"seconds_in_slot2\"]\n",
    "#gg.groupby(\"block_earlier\")[\"slot\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac3c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_late_performer_blobs(_df):\n",
    "    \n",
    "    df = _df.copy()\n",
    "    df = prepare_failed_with_size(df, only_failed=True, overwrite=False)\n",
    "    #df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "    df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "    #six = df[df[\"blobs\"] == 128*1024*6].copy()\n",
    "    hm = df[df[\"validator\"] >= 30_000].copy()\n",
    "    \n",
    "    def calculate_histogram(data, bins, x_range):\n",
    "        hist, bin_edges = np.histogram(data, bins=bins, range=x_range)\n",
    "        # Normalize to percentage\n",
    "        total_count = np.sum(hist)\n",
    "        hist_normalized = (hist / total_count) * 100\n",
    "        return bin_edges, hist_normalized\n",
    "    \n",
    "    qa = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot, min(event_date_time) event_date_time\n",
    "        FROM default.beacon_api_eth_v1_events_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {df.slot.min()}\n",
    "        group by slot\n",
    "        \"\"\"\n",
    "\n",
    "    res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "    \n",
    "    qa1 = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot\n",
    "        FROM default.canonical_beacon_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {df.slot.min()}\n",
    "    \"\"\"\n",
    "    res_can = request_query(qa1, [\"slot\"])\n",
    "    res = res[res[\"slot\"].isin(res_can.slot.unique())]\n",
    "    def parse_datetime(event_time_str):\n",
    "        return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "\n",
    "    res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "    res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "    \n",
    "    gg = pd.merge(df, res, how=\"left\", left_on=\"slot\", right_on=\"slot\")\n",
    "    gg[\"blobs\"] = gg[\"blobs\"] / (1024*128)\n",
    "\n",
    "\n",
    "    blobs = dict()\n",
    "    for i in range(0,7):\n",
    "        j = gg[gg[\"blobs\"] == i]\n",
    "        print(j.seconds_in_slot.mean())\n",
    "        blobs[i] = calculate_histogram(j.seconds_in_slot, 30, (0,4.1))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i, c in zip([1, 6], [0, 1]): # zip([0, 1, 6], [0, 1, 2]):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=blobs[i][0],\n",
    "            y=blobs[i][1],\n",
    "            fill='tozeroy',\n",
    "            mode='lines',\n",
    "            name=f\"blocks with {i} blob(s)\",\n",
    "            line=dict(color=COLORS3[c]),\n",
    "            opacity=1/(i+1)\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Blocks First Seen Timing <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        yaxis_title='%',\n",
    "        xaxis_title='seconds in slot',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            range=[0, 4.01]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = hist_late_performer_blobs(df)\n",
    "    fig.write_image(f\"{IMAGE}/hist_late_performer_blobs.png\")\n",
    "    if SHOW:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def calculate_kde(data, x_range):\n",
    "#    kde = gaussian_kde(data)\n",
    "#    x = np.linspace(x_range[0], x_range[1], 1000)\n",
    "#    y = kde(x)\n",
    "#    # Normalize the KDE to ensure the area under the curve is 1\n",
    "#    area = np.trapz(y, x)\n",
    "#    y_normalized = y / area * 100  # Scale to 100%\n",
    "#    return x, y_normalized\n",
    "#\n",
    "#x_jj, y_jj = calculate_kde(low['seconds_in_slot'], (0, 10))\n",
    "#x_rr, y_rr = calculate_kde(high['seconds_in_slot'], (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694c922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_late_performer(_df):   \n",
    "    df = _df.copy()\n",
    "    \n",
    "    df = prepare_failed_with_size(df, only_failed=True, overwrite=False)\n",
    "    #df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "    df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "    #hm = df[df[\"blobs\"] == 128*1024*6].copy()\n",
    "    hm = df[df[\"validator\"] >= 30_000].copy()\n",
    "    \n",
    "    qa = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot, min(event_date_time) event_date_time\n",
    "        FROM default.beacon_api_eth_v1_events_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {df.slot.min()}\n",
    "        group by slot\n",
    "        \"\"\"\n",
    "\n",
    "    res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "    def parse_datetime(event_time_str):\n",
    "        return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "\n",
    "    res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "    res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "    \n",
    "    high = res[res[\"slot\"].isin((hm[\"slot\"]).tolist())]\n",
    "    low = res[~res[\"slot\"].isin((hm[\"slot\"]).tolist())]\n",
    "    \n",
    "    def calculate_histogram(data, bins, x_range):\n",
    "        hist, bin_edges = np.histogram(data, bins=bins, range=x_range)\n",
    "        # Normalize to percentage\n",
    "        total_count = np.sum(hist)\n",
    "        hist_normalized = (hist / total_count) * 100\n",
    "        return bin_edges, hist_normalized\n",
    "\n",
    "    x_jj, y_jj = calculate_histogram(low['seconds_in_slot'], 50, (0, 10.1))\n",
    "    x_rr, y_rr = calculate_histogram(high['seconds_in_slot'], 50, (0, 10.1))\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add KDE plot for the first dataset\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_jj,\n",
    "        y=y_jj,\n",
    "        fill='tozeroy',\n",
    "        mode='lines',\n",
    "        name='Rest',\n",
    "        line=dict(color=COLORS3[0]),\n",
    "        opacity=0.5\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=x_rr,\n",
    "            y=y_rr,\n",
    "            fill='tozeroy',\n",
    "            mode='lines',\n",
    "            name=f'Weak Blocks (n={len(high)})',\n",
    "            line=dict(color=COLORS3[1]),\n",
    "            opacity=0.5\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Blocks First Seen Timing - Weak Blocks vs Rest <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        yaxis_title='%',\n",
    "        xaxis_title='seconds in slot',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            range=[0, 10.01]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = hist_late_performer(df)\n",
    "    fig.write_image(f\"{IMAGE}/hist_late_performer.png\")\n",
    "    if SHOW:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462c62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_late_performer_mevboost(_df):   \n",
    "    df = _df.copy()\n",
    "    \n",
    "    df = prepare_failed_with_size(df, only_failed=True, overwrite=False)\n",
    "    #df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "    df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "    hm = df[df[\"blobs\"] == 128*1024*6].copy()\n",
    "    hm = hm[hm[\"validator\"] >= 30_000].copy()\n",
    "    \n",
    "    qa = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot, min(event_date_time) event_date_time\n",
    "        FROM default.beacon_api_eth_v1_events_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {df.slot.min()}\n",
    "        group by slot\n",
    "        \"\"\"\n",
    "\n",
    "    res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "    def parse_datetime(event_time_str):\n",
    "        return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "\n",
    "    res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "    res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "    \n",
    "    \n",
    "    mevboost = pandas_gbq.read_gbq(f\"\"\"\n",
    "        SELECT distinct slot FROM `ethereum-data-nero.eth.mevboost` WHERE slot >= {df.slot.min()}\n",
    "        order by slot\n",
    "    \"\"\")\n",
    "    mevboost.to_parquet(f\"{DATA}/mevboost.parquet\", index=False)\n",
    "\n",
    "    mb = res[res[\"slot\"].isin(mevboost[\"slot\"])]\n",
    "    nmb = res[~res[\"slot\"].isin(mevboost[\"slot\"])]\n",
    "    \n",
    "    def calculate_histogram(data, bins, x_range):\n",
    "        hist, bin_edges = np.histogram(data, bins=bins, range=x_range)\n",
    "        # Normalize to percentage\n",
    "        total_count = np.sum(hist)\n",
    "        hist_normalized = (hist / total_count) * 100\n",
    "        return bin_edges, hist_normalized\n",
    "\n",
    "    x_jj, y_jj = calculate_histogram(mb['seconds_in_slot'], 50, (0, 4.1))\n",
    "    x_rr, y_rr = calculate_histogram(nmb['seconds_in_slot'], 50, (0, 4.1))\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add KDE plot for the first dataset\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_jj,\n",
    "        y=y_jj,\n",
    "        fill='tozeroy',\n",
    "        mode='lines',\n",
    "        name='MEV-Boost',\n",
    "        line=dict(color=COLORS3[0]),\n",
    "        opacity=0.5\n",
    "    ))\n",
    "    fig.add_trace(go.Scatter(\n",
    "            x=x_rr,\n",
    "            y=y_rr,\n",
    "            fill='tozeroy',\n",
    "            mode='lines',\n",
    "            name=f'Local Building',\n",
    "            line=dict(color=COLORS3[1]),\n",
    "            opacity=0.5\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Blocks First Seen Timing - MEV-Boost vs Local Building <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        yaxis_title='%',\n",
    "        xaxis_title='seconds in slot',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            range=[0, 4.01]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = hist_late_performer_mevboost(df)\n",
    "    fig.write_image(f\"{IMAGE}/hist_late_performer_mevboost.png\")\n",
    "    if SHOW:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5630d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_mevboost_relays(_df):\n",
    "    tt = _df.copy()\n",
    "\n",
    "    tt = prepare_failed_with_size(tt, only_failed=True, overwrite=False)\n",
    "    #tt = tt[tt[\"size_compressed_total\"] < 1_000_000]\n",
    "    tt[\"size_compressed_total\"] = tt[\"size_compressed_total\"] / 1024**2\n",
    "    hm = tt[tt[\"blobs\"] == 128*1024*6].copy()\n",
    "    hm = hm[hm[\"validator\"] >= 30_000].copy()\n",
    "\n",
    "    qa = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot, min(event_date_time) event_date_time\n",
    "        FROM default.beacon_api_eth_v1_events_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {tt.slot.min()}\n",
    "        group by slot\n",
    "        \"\"\"\n",
    "\n",
    "    res = request_query(qa, [\"slot\", \"event_date_time\"])\n",
    "    \n",
    "    qa1 = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            slot\n",
    "        FROM default.canonical_beacon_block\n",
    "        WHERE\n",
    "            slot_start_date_time > NOW() - INTERVAL '100 day'\n",
    "            and slot >= {df.slot.min()}\n",
    "    \"\"\"\n",
    "    res_can = request_query(qa1, [\"slot\"])\n",
    "    res = res[res[\"slot\"].isin(res_can.slot.unique())]\n",
    "    def parse_datetime(event_time_str):\n",
    "        return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "\n",
    "    res['event_date_time_unix'] = res['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "    res[\"seconds_in_slot\"] = res.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time_unix\"], x[\"slot\"]), axis=1)\n",
    "\n",
    "\n",
    "    mevboost = pandas_gbq.read_gbq(f\"\"\"\n",
    "        SELECT distinct slot, relay FROM `ethereum-data-nero.eth.mevboost` WHERE slot >= {tt.slot.min()}\n",
    "        order by slot\n",
    "    \"\"\")\n",
    "    tt = pd.merge(res, mevboost, how=\"left\", left_on=\"slot\", right_on=\"slot\")\n",
    "\n",
    "    def calculate_histogram(data, bins, x_range):\n",
    "            hist, bin_edges = np.histogram(data, bins=bins, range=x_range)\n",
    "            # Normalize to percentage\n",
    "            total_count = np.sum(hist)\n",
    "            hist_normalized = (hist / total_count) * 100\n",
    "            return bin_edges, hist_normalized\n",
    "\n",
    "    relays = dict()\n",
    "    for i in tt.relay.unique():\n",
    "        j = tt[tt[\"relay\"] == i]\n",
    "        print(i, j.seconds_in_slot.mean())\n",
    "        relays[i] = calculate_histogram(j.seconds_in_slot, 30, (0,4.1))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    col = [\n",
    "        '#377eb8',\n",
    "        '#ff7f00',\n",
    "     '#33a02c',\n",
    "     '#ff7f7f',\n",
    "     '#8dd3c7',\n",
    "     '#ffffb3',\n",
    "     '#bebada',\n",
    "     '#fb8072',\n",
    "     '#80b1d3',\n",
    "     '#fdb462'\n",
    "    ]\n",
    "    for ix, i in enumerate([\"ultrasound\", \"bloxroute (max profit)\", \"titan\"]):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=relays[i][0],\n",
    "            y=relays[i][1],\n",
    "            fill='tozeroy',\n",
    "            mode='lines',\n",
    "            name=f\"{i}\",\n",
    "            line=dict(color=col[ix]),\n",
    "            opacity=0.9\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Blocks First Seen Timing <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        yaxis_title='%',\n",
    "        xaxis_title='seconds in slot',\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"normal\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            range=[0, 4.01]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=IMAGE_HEIGHT,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=1,\n",
    "            y=1,\n",
    "            xanchor='right',\n",
    "            yanchor='top'\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "        #yaxis = dict(\n",
    "        #    type=\"log\"\n",
    "        #)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = hist_mevboost_relays(df)\n",
    "    fig.write_image(f\"{IMAGE}/hist_mevboost_relays.png\")\n",
    "    if SHOW:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_failed_and_size_scatter(_df):\n",
    "    #df = df.sample(1_000_000)\n",
    "    df = _df.copy()\n",
    "    df = prepare_failed_with_size(df, only_failed=True, overwrite=False)\n",
    "    df = df[df[\"size_compressed_total\"] < 1_000_000]\n",
    "    df[\"size_compressed_total\"] = df[\"size_compressed_total\"] / 1024**2\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fontfamily = \"Ubuntu Mono\"\n",
    "\n",
    "    # Adding traces for each slot\n",
    "    #fig.add_trace(go.Scatter(\n",
    "    #    x=df['slot'],\n",
    "    #    y=df['size'],\n",
    "    #    mode='markers',\n",
    "    #    name='Size',\n",
    "    #    marker=dict(size=8, color='blue')\n",
    "    #))\n",
    "    #\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df['validator'],\n",
    "        y=df['size_compressed_total'],\n",
    "        mode='markers',\n",
    "        name='Size Compressed',\n",
    "        marker=dict(size=2, color=COLORS[0])  # Adjust size and color\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': f'Failed {WHAT[0].upper()+WHAT[1:]} Votes vs. Block Size <span style=\"font-size: 16px;\">({slot_to_day(_df.slot.min())} - {slot_to_day(_df.slot.max())})</span>',\n",
    "            #'y':0.9,\n",
    "            #'x':0.5,\n",
    "            #'xanchor': 'center',\n",
    "            #'yanchor': 'top',\n",
    "            'font': dict(family=fontfamily, size=24, color='#333')\n",
    "        },\n",
    "        xaxis_title=f\"failed votes per slot\",\n",
    "        yaxis_title=\"compressed block size (incl. blobs)\",\n",
    "        font=dict(\n",
    "            family=fontfamily,\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridwidth=1, \n",
    "            gridcolor='LightGray',\n",
    "            zerolinecolor='gray',\n",
    "            #type=\"log\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridwidth=1, \n",
    "            gridcolor='LightGray',\n",
    "            zerolinecolor='gray'\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,    \n",
    "    )\n",
    "\n",
    "    blob_sizes = [i * 128/1024 for i in range(7)]\n",
    "    df[\"blobs\"] = df[\"blobs\"] / 1024**2\n",
    "    obs_counts = df.groupby(\"blobs\")[\"slot\"].count().to_dict()\n",
    "\n",
    "    texts = []\n",
    "    for i, size in enumerate(blob_sizes):\n",
    "        print(len(str(obs_counts[size])))\n",
    "        if len(str(obs_counts[size])) == 5:\n",
    "            texts.append(f\"{'n=':>8}{obs_counts[size]:<6,}\")\n",
    "        else:\n",
    "            texts.append(f\"{'n=':<4}{obs_counts[size]:<6,}\")\n",
    "\n",
    "\n",
    "    for i, (size, text) in enumerate(zip(blob_sizes, texts)):\n",
    "        fig.add_annotation(\n",
    "            text=text,\n",
    "            xref=\"paper\",\n",
    "            yref=\"y\",\n",
    "            x=1.05,\n",
    "            y=size + 80/1024,\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                family=fontfamily,\n",
    "                size=FONTSIZE-2,\n",
    "                color=\"black\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if WHAT != \"source\":\n",
    "    fig = missed_failed_and_size_scatter(df)\n",
    "    fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_size_scatter.png\")\n",
    "    #if SHOW:\n",
    "        #fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missed_failed_boxplots(_df):\n",
    "    df = prepare_failed_with_size(_df.copy(), only_failed=True if WHAT != \"source\" else False).dropna()\n",
    "    df[\"nr_blobs\"] = df[\"blobs\"]/(128*1024)\n",
    "    \n",
    "    def percentile(n):\n",
    "        def percentile_(x):\n",
    "            return np.percentile(x, n)\n",
    "        percentile_.__name__ = 'percentile_%s' % n\n",
    "        return percentile_\n",
    "\n",
    "    aggr = {\n",
    "        \"validator\": [\"mean\", \"median\", \"min\", percentile(5), percentile(95), \"max\"]\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    result = df.groupby(\"nr_blobs\").agg(aggr).reset_index()\n",
    "    result.columns = ['_'.join(col).strip() for col in result.columns.values]\n",
    "    print(result[\"validator_percentile_95\"].max())\n",
    "\n",
    "    for nr_blob in df['nr_blobs'].unique():\n",
    "        fig.add_trace(go.Box(\n",
    "            x=[nr_blob] * df[df['nr_blobs'] == nr_blob].shape[0],\n",
    "            y=df[df['nr_blobs'] == nr_blob]['validator'],\n",
    "            name=str(nr_blob),\n",
    "                boxpoints=False, # no data points\n",
    "\n",
    "            marker_color=COLORS[1],  # Set box line color\n",
    "            #boxmean='sd',\n",
    "            line_color = COLORS[0]\n",
    "        ))\n",
    "\n",
    "    # Update the layout for better readability\n",
    "    fig.update_layout(\n",
    "        title=f'Missed Head Votes over Blobs per Block <span style=\"font-size: 16px;\">({slot_to_day(df.slot.min())} - {slot_to_day(df.slot.max())})</span>',\n",
    "        xaxis_title=\"number of blobs\",\n",
    "        showlegend=False,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=FONTSIZE,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[0, 180],\n",
    "            title=\"missed/failed head votes\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey'\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey'\n",
    "        ),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        \n",
    "    )\n",
    "    obs_counts = df.groupby(\"nr_blobs\")[\"slot\"].count().to_dict()\n",
    "    texts = []\n",
    "    for i, size in enumerate(df['nr_blobs'].unique()):\n",
    "        print(len(str(obs_counts[size])))\n",
    "        if len(str(obs_counts[size])) == 5:\n",
    "            texts.append(f\"{'n=':>8}{obs_counts[size]:<6,}\")\n",
    "        else:\n",
    "            texts.append(f\"{'n=':<4}{obs_counts[size]:<6,}\")\n",
    "            \n",
    "            \n",
    "    for i, (size, text) in enumerate(zip(df['nr_blobs'].unique(), texts)):\n",
    "        fig.add_annotation(\n",
    "            text=text,\n",
    "            xref=\"x\",\n",
    "            yref=\"y\",\n",
    "            x=i+0.2,\n",
    "            y=170,\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=FONTSIZE-1,\n",
    "                color=\"black\"\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = missed_failed_boxplots(df)\n",
    "    fig.write_image(f\"{IMAGE}/failed_missed_{WHAT}_size_boxplot.png\")\n",
    "    #if SHOW:\n",
    "    #    fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffa9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples_for_late_inclusion(_df):\n",
    "    gg = pd.DataFrame()\n",
    "    for ix, i in enumerate(sorted(_df.epoch.unique())):\n",
    "        #print(f\"{ix}/{l}\", end=\"\\r\")\n",
    "        #if ix > 3:\n",
    "        #    break\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        g = pd.merge(g, clients_final, how=\"left\", left_on=\"validators\", right_on=\"validator_id\")\n",
    "        g[\"cl_client\"] = g[\"cl_client\"].fillna(\"Unknown\")\n",
    "        #g = g.groupby([\"cl_client\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        gg = pd.concat([gg, g], ignore_index=True)\n",
    "        if ix > 15:\n",
    "            print(\"examples with late inclusion\")\n",
    "            print(g[g[\"distance\"] > 30].groupby([\"slot\", \"distance\"])[\"validators\"].count().reset_index().sort_values(\"validators\", ascending=False))\n",
    "            break\n",
    "    return gg\n",
    "       \n",
    "if WHAT == \"head\":\n",
    "    hh = show_examples_for_late_inclusion(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbd09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WHAT == \"head\":\n",
    "    try:\n",
    "        raise\n",
    "        proposers = pd.read_parquet(f\"{DATA}/proposers.parquet\")\n",
    "        print(\"read locally\")\n",
    "    except:\n",
    "        proposers = pandas_gbq.read_gbq(f\"\"\"\n",
    "            SELECT distinct slot, validator_id FROM `ethereum-data-nero.ethdata.beaconchain` WHERE slot >= {df.slot.min()}\n",
    "            order by slot\n",
    "        \"\"\")\n",
    "        proposers.to_parquet(f\"{DATA}/proposers.parquet\", index=False)\n",
    "\n",
    "    proposers.columns = [\"slot\", \"proposer_id\"]\n",
    "    clients_final[\"validator_id\"] = clients_final[\"validator_id\"].astype(int)\n",
    "    proposers[\"proposer_id\"] = proposers[\"proposer_id\"].astype(int)\n",
    "    ee = pd.merge(proposers, clients_final, how=\"left\", left_on=\"proposer_id\", right_on=\"validator_id\")\n",
    "    ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_delay_proposers(df):\n",
    "    startslot = min(df.slot)\n",
    "    endslot = max(df.slot)\n",
    "    gg = list()\n",
    "    l = len(df.epoch.unique())\n",
    "    try:\n",
    "        proposers = pd.read_parquet(f\"{DATA}/proposers.parquet\").drop_duplicates()\n",
    "        print(\"read locally\")\n",
    "    except:\n",
    "        proposers = pandas_gbq.read_gbq(f\"\"\"\n",
    "            SELECT distinct slot, validator_id FROM `ethereum-data-nero.ethdata.beaconchain` WHERE slot >= {df.slot.min()}\n",
    "            order by slot\n",
    "        \"\"\")\n",
    "        proposers.to_parquet(f\"{DATA}/proposers.parquet\", index=False)\n",
    "\n",
    "    proposers.columns = [\"slot\", \"proposer_id\"]\n",
    "    clients_final[\"validator_id\"] = clients_final[\"validator_id\"].astype(int)\n",
    "    proposers[\"proposer_id\"] = proposers[\"proposer_id\"].astype(int)\n",
    "    ee = pd.merge(proposers, clients_final, how=\"left\", left_on=\"proposer_id\", right_on=\"validator_id\")\n",
    "    for ix, i in enumerate(sorted(df.epoch.unique(), reverse=True)):\n",
    "        print(f\"{ix}/{l}\", end=\"\\r\")\n",
    "        #if ix > 10:\n",
    "        #    break\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        g = pd.merge(g, clients_final, how=\"left\", left_on=\"validators\", right_on=\"validator_id\")\n",
    "        g[\"cl_client\"] = g[\"cl_client\"].fillna(\"Unknown\")\n",
    "        #g = g.groupby([\"cl_client\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        #gg = pd.concat([gg, g], ignore_index=True)\n",
    "\n",
    "        g['re-included'] = True\n",
    "        min_distance_idx = g.groupby(['slot', 'validators'])['distance'].idxmin()\n",
    "        g.loc[min_distance_idx, 're-included'] = False\n",
    "        #print(len(g[g[\"re-included\"] == True]))\n",
    "        g[\"sp\"] = g[\"slot\"] + g[\"distance\"]\n",
    "        g = pd.merge(g[g[\"re-included\"] == True], ee, left_on=\"sp\", right_on=\"slot\")\n",
    "        #print(g)\n",
    "        #g = pd.merge(g, ee, left_on=\"sp\", right_on=\"slot\")\n",
    "        g = g.groupby([\"cl_client_y\", \"distance\"])[\"slot_x\"].count().reset_index()\n",
    "        g.columns=[\"cl_client\", \"distance\", \"slot\"]\n",
    "        gg.append(g)\n",
    "        \n",
    "    gg = pd.concat(gg, ignore_index=True)\n",
    "    gg.to_parquet(f\"{DATA}/{TMP}/correct_delay_proposers.parquet\", index=False)\n",
    "    \n",
    "    gg = gg.groupby([\"cl_client\", \"distance\"])[\"slot\"].sum().reset_index()\n",
    "\n",
    "    gg[\"per\"] = gg[\"slot\"]/ gg[\"slot\"].sum() * 100\n",
    "    \n",
    "    #gg[\"distance\"] = gg[\"distance\"] -1\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, i in enumerate(gg.cl_client.unique()):\n",
    "        _gg = gg[gg[\"cl_client\"] == i].copy()\n",
    "        fig.add_trace(go.Bar(\n",
    "            x= _gg[_gg[\"distance\"] != 1][\"distance\"],\n",
    "            y= _gg[_gg[\"distance\"] != 1][\"per\"],\n",
    "            marker_color=COLORS[ix],\n",
    "            name=f'{i}',\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "            title_text=f'Re-Submitted Attestation Inclusion Delay <span style=\"font-size: 16px;\">({slot_to_day(startslot)} - {slot_to_day(endslot)})</span>',\n",
    "            legend=dict(x=0.87, y=1),\n",
    "            barmode='stack',\n",
    "            legend_traceorder=\"reversed\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                title=\"delay in slots\",\n",
    "                range=[1.5, 63]\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"% of attestations\",\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                #type=\"log\",\n",
    "                #range=[0,1]\n",
    "\n",
    "            ),\n",
    "            height=550,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=FONTSIZE,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "        )\n",
    "    #fig.add_annotation(\n",
    "    #    text=f'0 slot inclusion: {gg[gg[\"distance\"] == 0][\"per\"].sum():,.2f}%',\n",
    "    #    xref=\"paper\",\n",
    "    #    yref=\"paper\",\n",
    "    #    x=1,\n",
    "    #    y=1,\n",
    "    #    showarrow=False,\n",
    "    #    font=dict(\n",
    "    #        family=\"Ubuntu Mono\",\n",
    "    #        size=18,\n",
    "    #        color=\"black\"\n",
    "    #    )\n",
    "    #)\n",
    "    return fig\n",
    "if WHAT == \"head\":\n",
    "    fig = correct_delay_proposers(df)\n",
    "    fig.write_image(f\"{IMAGE}/correct_{WHAT}_delay_clients_proposers.png\")\n",
    "    if SHOW:\n",
    "        fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243381a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct__delay_reinclusion(df):\n",
    "    startslot = 9271808\n",
    "    endslot = max(df.slot)\n",
    "    gg = []\n",
    "    l = len(df.epoch.unique())\n",
    "    for ix, i in enumerate(sorted(df.epoch.unique())):\n",
    "        print(f\"{ix}/{l}\", end=\"\\r\")\n",
    "        #if ix > 13:\n",
    "        #    break\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        #g = g.groupby([\"cl_client\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        g['re-included'] = \"reinclusion\"\n",
    "        min_distance_idx = g.groupby(['slot', 'validators'])['distance'].idxmin()\n",
    "        g.loc[min_distance_idx, 're-included'] = \"first inclusion\"\n",
    "        g = g.groupby([\"re-included\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        gg.append(g)\n",
    "        \n",
    "    gg = pd.concat(gg, ignore_index=True)\n",
    "    gg.to_parquet(f\"{DATA}/{TMP}/correct__delay_reinclusion.parquet\", index=False)\n",
    "\n",
    "    gg = gg.groupby([\"re-included\", \"distance\"])[\"slot\"].sum().reset_index()\n",
    "    \n",
    "    gg[\"per\"] = gg[\"slot\"]/ gg[\"slot\"].sum() * 100\n",
    "    \n",
    "    #gg[\"distance\"] = gg[\"distance\"] -1\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, i in enumerate(gg[\"re-included\"].unique()):\n",
    "        _gg = gg[gg[\"re-included\"] == i]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x= _gg[_gg[\"distance\"] != 1][\"distance\"],\n",
    "            y= _gg[_gg[\"distance\"] != 1][\"per\"],\n",
    "            marker_color=COLORS[ix],\n",
    "            name=f'{i}',\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        title_text=f'Attestation Inclusion Delay <span style=\"font-size: 14px;\">({slot_to_day(startslot)} - {slot_to_day(endslot)})</span>',\n",
    "        legend=dict(x=0.82, y=0.9),\n",
    "        barmode='stack',\n",
    "        legend_traceorder=\"reversed\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=\"delay in slots\",\n",
    "            range=[1.5, 63]\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"% of attestations\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            #type=\"log\",\n",
    "            #range=[0,1]\n",
    "\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=18,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        text=f'1 slot inclusion: {gg[gg[\"distance\"] == 1][\"per\"].sum():,.2f}%',\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=1,\n",
    "        y=1,\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=18,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "if WHAT == \"head\":\n",
    "    fig = correct__delay_reinclusion(df)\n",
    "    fig.write_image(f\"{IMAGE}/correct_{WHAT}_delay_reinclusion.png\")\n",
    "    if SHOW:\n",
    "        fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct__delay_reinclusion_per(df):\n",
    "    startslot = 9271808\n",
    "    endslot = max(df.slot)\n",
    "    gg = []\n",
    "    l = len(df.epoch.unique())\n",
    "    for ix, i in enumerate(sorted(df.epoch.unique())):\n",
    "        print(f\"{ix}/{l}\", end=\"\\r\")\n",
    "        #if ix > 130:\n",
    "        #    break\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        #g = g.groupby([\"cl_client\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        g['re-included'] = \"reinclusion\"\n",
    "        min_distance_idx = g.groupby(['slot', 'validators'])['distance'].idxmin()\n",
    "        g.loc[min_distance_idx, 're-included'] = \"first inclusion\"\n",
    "        g = g.groupby([\"re-included\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        gg.append(g)\n",
    "        \n",
    "    gg = pd.concat(gg, ignore_index=True)\n",
    "\n",
    "    gg = gg.groupby([\"re-included\", \"distance\"])[\"slot\"].sum().reset_index()\n",
    "    \n",
    "    total = gg.groupby(\"distance\")[\"slot\"].sum().to_dict()\n",
    "    \n",
    "    gg[\"slot\"] = gg.apply(lambda x: x[\"slot\"] / total[x[\"distance\"]] * 100, axis=1)\n",
    "    \n",
    "    gg[\"per\"] = gg[\"slot\"]/ gg[\"slot\"].sum() * 100\n",
    "    \n",
    "    #gg[\"distance\"] = gg[\"distance\"] -1\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, i in enumerate(gg[\"re-included\"].unique()):\n",
    "        _gg = gg[gg[\"re-included\"] == i]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x= _gg[\"distance\"],\n",
    "            y= _gg[\"slot\"],\n",
    "            marker_color=COLORS[ix],\n",
    "            name=f'{i}',\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "            title_text=f'Attestation Vote Inclusion Delay - Percentage over Slot Delay <span style=\"font-size: 14px;\">({slot_to_day(startslot)} - {slot_to_day(endslot)})</span>',\n",
    "            legend=dict(x=0.82, y=0.9),\n",
    "            barmode='stack',\n",
    "            legend_traceorder=\"reversed\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                title=\"delay in slots\",\n",
    "                range=[-0.75, 62]\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"% attestations\",\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                #type=\"log\",\n",
    "                #range=[0,1]\n",
    "\n",
    "            ),\n",
    "            height=550,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "        )\n",
    "    #fig.add_annotation(\n",
    "    #    text=f'0 slot inclusion: {gg[gg[\"distance\"] == 0][\"per\"].sum():,.2f}%',\n",
    "    #    xref=\"paper\",\n",
    "    #    yref=\"paper\",\n",
    "    #    x=1,\n",
    "    #    y=1,\n",
    "    #    showarrow=False,\n",
    "    #    font=dict(\n",
    "    #        family=\"Ubuntu Mono\",\n",
    "    #        size=18,\n",
    "    #        color=\"black\"\n",
    "    #    )\n",
    "    #)\n",
    "    return fig\n",
    "if WHAT == \"head\":\n",
    "    fig = correct__delay_reinclusion_per(df)\n",
    "    fig.write_image(f\"{IMAGE}/correct_{WHAT}_delay_reinclusion_per.png\")\n",
    "    if SHOW:\n",
    "        fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5f95a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def correct_delay_clients(df):\n",
    "    startslot = 9271808\n",
    "    endslot = max(df.slot)\n",
    "    gg = pd.DataFrame()\n",
    "    l = len(df.epoch.unique())\n",
    "    for ix, i in enumerate(sorted(df.epoch.unique())):\n",
    "        print(f\"{ix}/{l}\", end=\"\\r\")\n",
    "        #if ix > 3:\n",
    "        #    break\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        g = pd.merge(g, clients_final, how=\"left\", left_on=\"validators\", right_on=\"validator_id\")\n",
    "        g[\"cl_client\"] = g[\"cl_client\"].fillna(\"Unknown\")\n",
    "        g = g.groupby([\"cl_client\", \"distance\"])[\"slot\"].count().reset_index()\n",
    "        gg = pd.concat([gg, g], ignore_index=True)\n",
    "\n",
    "    gg = gg.groupby([\"cl_client\", \"distance\"])[\"slot\"].sum().reset_index()\n",
    "    gg[\"per\"] = gg[\"slot\"]/ gg[\"slot\"].sum() * 100\n",
    "    \n",
    "    #gg[\"distance\"] = gg[\"distance\"] -1\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for ix, i in enumerate(gg.cl_client.unique()):\n",
    "        _gg = gg[gg[\"cl_client\"] == i]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x= _gg[_gg[\"distance\"] != 1][\"distance\"],\n",
    "            y= _gg[_gg[\"distance\"] != 1][\"per\"],\n",
    "            marker_color=COLORS[ix],\n",
    "            name=f'{i}',\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "            title_text=f'Attestation Inclusion Delay <span style=\"font-size: 14px;\">({slot_to_day(startslot)} - {slot_to_day(endslot)})</span>',\n",
    "            legend=dict(x=0.87, y=0.9),\n",
    "            barmode='stack',\n",
    "            legend_traceorder=\"reversed\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                title=\"delay in slots\",\n",
    "                range=[0.5, 63]\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"% of attestations\",\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                #type=\"log\",\n",
    "                #range=[0,1]\n",
    "\n",
    "            ),\n",
    "            height=550,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "        )\n",
    "    fig.add_annotation(\n",
    "        text=f'1 slot inclusion: {gg[gg[\"distance\"] == 0][\"per\"].sum():,.2f}%',\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=1,\n",
    "        y=1,\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=18,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "if WHAT == \"head\":\n",
    "    fig = correct_delay_clients(df)\n",
    "    fig.write_image(f\"{IMAGE}/correct_{WHAT}_delay_clients.png\")\n",
    "    if SHOW:\n",
    "        fig.show()\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd6069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def correct_delay(df):\n",
    "    startslot = 9271808\n",
    "    endslot = max(df.slot)\n",
    "    gg = pd.DataFrame()\n",
    "    for i in sorted(df.epoch.unique()):\n",
    "        print(i)\n",
    "        g = pd.read_parquet(f\"{DATA}/correct_{WHAT}/{i}.parquet\").drop_duplicates()\n",
    "        g = g[g[\"validators\"] != 999999999999999]\n",
    "        g = g.groupby(\"distance\")[\"validators\"].count().reset_index()\n",
    "        gg = pd.concat([gg, g], ignore_index=True)\n",
    "\n",
    "    gg = gg.groupby(\"distance\")[\"validators\"].sum().reset_index()\n",
    "    gg[\"per\"] = gg[\"validators\"]/ gg[\"validators\"].sum() * 100\n",
    "    \n",
    "    #gg[\"distance\"] = gg[\"distance\"] -1\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x= gg[gg[\"distance\"] != 1][\"distance\"],\n",
    "        y= gg[gg[\"distance\"] != 1][\"per\"],\n",
    "        marker_color=COLORS[0],\n",
    "        name='Performance Delta comparing `Actual` with `Expected`',\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "            title_text=f'{WHAT[0].upper() + WHAT[1:]} Vote Inclusion Delay <span style=\"font-size: 14px;\">({slot_to_day(startslot)} - {slot_to_day(endslot)})</span>',\n",
    "            legend=dict(x=0, y=1),\n",
    "            barmode='group',\n",
    "            legend_traceorder=\"reversed\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                title=\"Delay in Slots\",\n",
    "                range=[1.5, 63]\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"% of validators\",\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "                #type=\"log\"\n",
    "\n",
    "            ),\n",
    "            height=550,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "\n",
    "        )\n",
    "    fig.add_annotation(\n",
    "        text=f'0 slot inclusion: {gg[gg[\"distance\"] == 0].iloc[0][\"per\"]:,.2f}%',\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=0.98,\n",
    "        y=1,\n",
    "        showarrow=False,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=18,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "#fig = correct_delay(df)\n",
    "#fig.write_image(f\"{IMAGE}/correct_{WHAT}_delay.png\")\n",
    "#if SHOW:\n",
    "#    fig.show()\n",
    "#print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_correct_attestations(epoch, what=\"head\"):\n",
    "#    _df = pd.read_parquet(f\"{DATA}/correct_{what}/{epoch}.parquet\").reset_index(drop=True)\n",
    "#    if not _df.slot.nunique() == 32:\n",
    "#        return False\n",
    "#    return _df\n",
    "#\n",
    "#def query_attestations(slot):\n",
    "#    if slot > END_SLOT:\n",
    "#        raise\n",
    "#    _slot0 = slot // 32 * 32\n",
    "#    _slot1 = _slot0 + 32\n",
    "#    print(f\"query_attestations(); slot at {slot}\")\n",
    "#    _query_attestations = f\"\"\"\n",
    "#    SELECT DISTINCT\n",
    "#        block_slot, slot, validators, source_root, target_root, beacon_block_root\n",
    "#    FROM default.canonical_beacon_elaborated_attestation\n",
    "#    WHERE\n",
    "#        event_date_time > NOW() - INTERVAL '100 day'\n",
    "#        AND meta_network_name = 'mainnet'\n",
    "#        AND slot >= {_slot0}\n",
    "#        AND slot < {_slot1}\n",
    "#    \"\"\"\n",
    "#    return _query_attestations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e6fc9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#qa = query_attestations((END_SLOT-7200)//32*32)\n",
    "#res = request_query(qa, [\"block_slot\", \"slot\", \"validators\", \"source_root\", \"target_root\", \"beacon_block_root\"])\n",
    "#res[\"validators\"] = res[\"validators\"].apply(lambda x: eval(x))\n",
    "#for attestation_slot in res.slot.unique():\n",
    "#    print(attestation_slot)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e37db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def hex_to_rgba(hex_color, alpha=1.0):\n",
    "#    hex_color = hex_color.lstrip('#')\n",
    "#    return f'rgba({int(hex_color[0:2], 16)}, {int(hex_color[2:4], 16)}, {int(hex_color[4:6], 16)}, {alpha})'\n",
    "#\n",
    "#def weak_timing_chart(_df):\n",
    "#    #df = df.sample(1_000_000)\n",
    "#    df = _df.copy()\n",
    "#    gg = df.groupby(\"slot\")[\"validator\"].nunique().reset_index().sort_values(\"validator\")\n",
    "#    gg[\"per_voting_wrong\"] = gg[\"validator\"]/32175*100\n",
    "#    block_timing = load_timing_data(df, overwrite=OVERWRITE, rounding=3)\n",
    "#    gg = pd.merge(gg, block_timing, left_on=\"slot\", right_on=\"slot\")\n",
    "#    gg = gg[gg[\"time_in_slot\"] > 0]\n",
    "#    gg = gg[[\"slot\", \"per_voting_wrong\", \"time_in_slot\"]]\n",
    "#    mev = pandas_gbq.read_gbq(f\"\"\"\n",
    "#        SELECT distinct slot, builder FROM `ethereum-data-nero.eth.mevboost_db` WHERE slot >= {df.slot.min()}\n",
    "#        order by slot\n",
    "#    \"\"\")\n",
    "#    gg = pd.merge(gg, mev, left_on=\"slot\", right_on=\"slot\")\n",
    "#    largest = gg.groupby(\"builder\")[\"slot\"].count().reset_index().sort_values(\"slot\", ascending=False)[\"builder\"].tolist()[0:10]\n",
    "#\n",
    "#    \n",
    "#    fig = go.Figure()\n",
    "#\n",
    "#    fontfamily = \"Ubuntu Mono\"\n",
    "#    builder_colors= {i: COLORS3[ix] for ix, i in enumerate(gg.builder.unique())}\n",
    "#\n",
    "#    for builder in largest[:3]:\n",
    "#        color = builder_colors[builder]\n",
    "#        builder_df = gg[gg['builder'] == builder].sample(21000)\n",
    "#        fig.add_trace(go.Scatter(\n",
    "#            x=builder_df['time_in_slot'],\n",
    "#            y=builder_df['per_voting_wrong'],\n",
    "#            mode='markers',\n",
    "#            name=builder,\n",
    "#            marker=dict(size=4, color=hex_to_rgba(color, 0.3)),\n",
    "#        ))\n",
    "#\n",
    "#    fig.update_layout(\n",
    "#        title={\n",
    "#            'text': f'Failed {WHAT[0].upper()+WHAT[1:]} Votes vs. Block Size <span style=\"font-size: 16px;\">({slot_to_day(_df.slot.min())} - {slot_to_day(_df.slot.max())})</span>',\n",
    "#            'font': dict(family=fontfamily, size=24, color='#333')\n",
    "#        },\n",
    "#        xaxis_title=\"failed votes per slot\",\n",
    "#        yaxis_title=\"compressed block size (incl. blobs)\",\n",
    "#        font=dict(\n",
    "#            family=fontfamily,\n",
    "#            size=FONTSIZE,\n",
    "#            color=\"black\"\n",
    "#        ),\n",
    "#        legend=dict(\n",
    "#            font=dict(size=16),\n",
    "#            itemsizing='constant',\n",
    "#            tracegroupgap=5,\n",
    "#        ),\n",
    "#        paper_bgcolor='white',\n",
    "#        plot_bgcolor='white',\n",
    "#        xaxis=dict(\n",
    "#            showgrid=True,\n",
    "#            gridwidth=1,\n",
    "#            gridcolor='LightGray',\n",
    "#            zerolinecolor='gray',\n",
    "#        ),\n",
    "#        yaxis=dict(\n",
    "#            showgrid=True,\n",
    "#            gridwidth=1,\n",
    "#            gridcolor='LightGray',\n",
    "#            zerolinecolor='gray',\n",
    "#           # type=\"log\"\n",
    "#        ),\n",
    "#        showlegend=True,\n",
    "#        height=550,\n",
    "#        width=1200,\n",
    "#    )\n",
    "#    return fig\n",
    "#\n",
    "#if WHAT != \"source\":\n",
    "#    fig = weak_timing_chart(df)\n",
    "#    fig.write_image(f\"{IMAGE}/{WHAT}_weak_timing_chart.png\")\n",
    "#    #if SHOW:\n",
    "#        #fig.show()\n",
    "#    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c25cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(12, 20))\n",
    "#\n",
    "#joyplot(\n",
    "#    data=gg[gg[\"builder\"].isin(largest[:3])],\n",
    "#    by='builder',\n",
    "#    overlap=0.5,\n",
    "#    column='time_in_slot',\n",
    "#    figsize=(12, 20),\n",
    "#    colormap={i: COLORS3[ix] for ix, i in enumerate(gg.builder.unique())},\n",
    "#    #x_range=[0, 8],\n",
    "#    alpha=0.5,\n",
    "#    ax=ax\n",
    "#)\n",
    "#\n",
    "#plt.xlabel('seconds in slot')\n",
    "#plt.grid(True, axis='x')\n",
    "#plt.text(-0.95, 1.0, f'Head Vote Seen Timing over Seconds In Slot (epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})', fontsize=20, ha='left', va='top', fontweight='bold', fontfamily='Ubuntu Mono')\n",
    "#\n",
    "#plt.savefig(f\"{IMAGE}/{WHAT}_weak_timing_chart.png\", format='png', transparent=True)\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def weak_timing_chart(_df):\n",
    "#    df = _df.copy()\n",
    "#    \n",
    "#    fig = go.Figure()\n",
    "#\n",
    "#    fontfamily = \"Ubuntu Mono\"\n",
    "#    builder_colors = {i: COLORS3[ix] for ix, i in enumerate(gg.builder.unique())}\n",
    "#\n",
    "#    # Aggregate data from all builders\n",
    "#    aggregated_time_in_slot = []\n",
    "#    aggregated_per_voting_wrong = []\n",
    "#\n",
    "#    for builder in largest[:1]:\n",
    "#        builder_df = df[df['builder'] == builder]\n",
    "#        aggregated_time_in_slot.extend(builder_df['time_in_slot'])\n",
    "#        aggregated_per_voting_wrong.extend(builder_df['per_voting_wrong'])\n",
    "#    \n",
    "#    # Create a single 2D histogram\n",
    "#    fig.add_trace(go.Histogram2d(\n",
    "#        x=aggregated_time_in_slot,\n",
    "#        y=aggregated_per_voting_wrong,\n",
    "#        colorscale='Viridis',\n",
    "#        nbinsx=10,  # Number of bins in x-direction\n",
    "#        nbinsy=10,  # Number of bins in y-direction\n",
    "#        colorbar=dict(title='Count')\n",
    "#    ))\n",
    "#\n",
    "#    fig.update_layout(\n",
    "#        title={\n",
    "#            'text': f'Failed {WHAT[0].upper()+WHAT[1:]} Votes vs. Block Size <span style=\"font-size: 16px;\">({slot_to_day(_df.slot.min())} - {slot_to_day(_df.slot.max())})</span>',\n",
    "#            'font': dict(family=fontfamily, size=24, color='#333')\n",
    "#        },\n",
    "#        xaxis_title=\"failed votes per slot\",\n",
    "#        yaxis_title=\"compressed block size (incl. blobs)\",\n",
    "#        font=dict(\n",
    "#            family=fontfamily,\n",
    "#            size=FONTSIZE,\n",
    "#            color=\"black\"\n",
    "#        ),\n",
    "#        legend=dict(\n",
    "#            font=dict(size=16),  # Increase the font size of the legend\n",
    "#            itemsizing='constant',  # Ensures that the legend items are sized properly\n",
    "#            tracegroupgap=5,  # Increase the space between legend items\n",
    "#        ),\n",
    "#        paper_bgcolor='white',\n",
    "#        plot_bgcolor='white',\n",
    "#        xaxis=dict(\n",
    "#            showgrid=True,\n",
    "#            gridwidth=1,\n",
    "#            gridcolor='LightGray',\n",
    "#            zerolinecolor='gray',\n",
    "#        ),\n",
    "#        yaxis=dict(\n",
    "#            showgrid=True,\n",
    "#            gridwidth=1,\n",
    "#            gridcolor='LightGray',\n",
    "#            zerolinecolor='gray',\n",
    "#            # type=\"log\"\n",
    "#        ),\n",
    "#        showlegend=True,\n",
    "#        height=550,\n",
    "#        width=1200,\n",
    "#    )\n",
    "#    return fig\n",
    "#\n",
    "#if WHAT != \"source\":\n",
    "#    fig = weak_timing_chart(gg)\n",
    "#    fig.write_image(f\"{IMAGE}/{WHAT}_weak_timing_chart.png\")\n",
    "#    #if SHOW:\n",
    "#        #fig.show()\n",
    "#    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d1430",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"start check\")\n",
    "slots = sorted(df.slot.unique(), reverse=True)\n",
    "last = slots[0] +1\n",
    "for i in slots:\n",
    "    if last -1 != i:\n",
    "        print(i)\n",
    "        \n",
    "    last = i\n",
    "print(\"end check\")\n",
    "df = None\n",
    "block_timing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DO_PERFORMERS:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443d22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ADD_MORE = False\n",
    "ADD_MAX = 225*3\n",
    "USE_MAX = 225*2*32\n",
    "\n",
    "CORRECT_HEAD_TIMING = \"correct_head_timing\"\n",
    "\n",
    "wt = sorted([int(i.split(\".\")[0]) for i in os.listdir(f\"{DATA}/{CORRECT_HEAD_TIMING}\")], reverse=True)\n",
    "\n",
    "def get_time_in_curr_slot(ts, slot):\n",
    "    return (ts - (1654824023000 + (slot-1-4e6)*12000) - 12000) / 1000 \n",
    "\n",
    "def parse_datetime(event_time_str):\n",
    "    return datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').replace(tzinfo=pytz.UTC).timestamp()*1000\n",
    "\n",
    "def get_time_in_curr_slot2(event_time_str, slot):\n",
    "    event_time = datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S.%f').timestamp()*1000\n",
    "    return (event_time - (1654824023000 + (slot-1-4e6)*12000) - 12000) / 1000 \n",
    "\n",
    "if \"labels\" not in globals():\n",
    "    labels=None\n",
    "    \n",
    "def get_timing_dataset():\n",
    "    global labels\n",
    "    try:\n",
    "        df = pd.read_parquet(f\"{DATA}/{TMP}/correct_{WHAT}_timing.parquet\").drop_duplicates()\n",
    "        #df.drop(\"event_date_time\", axis=1, inplace=True)\n",
    "        \n",
    "        #df[\"epoch\"] = df[\"slot\"] //32\n",
    "        #print(df.epoch.nunique())\n",
    "        df = df[df[\"slot\"] >= (df.slot.max() - USE_MAX)//32*32]\n",
    "        #print(df.epoch.nunique())\n",
    "        #h = df.groupby(\"epoch\")[\"slot\"].nunique().reset_index()\n",
    "        known_epochs = set(df[\"slot\"].unique() // 32)\n",
    "        #df.drop(\"epoch\", axis=1, inplace=True)\n",
    "        #known_epochs = set(df.slot // 32)\n",
    "        print(f\"{DATA}/{TMP}/correct_{WHAT}_timing.parquet loaded locally\")\n",
    "        print(f\"{len(known_epochs)} epochs known\")\n",
    "        l = len(known_epochs)\n",
    "        #print(f\"storing dataset {DATA}/{TMP}/correct_{WHAT}_timing.parquet\")\n",
    "        #df.drop_duplicates(inplace=True)\n",
    "        #df.to_parquet(f\"{DATA}/{TMP}/correct_{WHAT}_timing.parquet\", index=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        df = pd.DataFrame()\n",
    "        known_epochs = set()\n",
    "\n",
    "    change=False\n",
    "    try:\n",
    "        if ADD_MORE:\n",
    "            lastepoch = None\n",
    "            for ix, epoch in enumerate(wt):\n",
    "                if ix == 0:\n",
    "                    lastepoch = epoch\n",
    "                else:\n",
    "                    if lastepoch - 1 != epoch:\n",
    "                        print(\"exit\")\n",
    "                        raise\n",
    "                    else:\n",
    "                        lastepoch = epoch\n",
    "                if epoch in known_epochs:\n",
    "                    continue\n",
    "                #if epoch > 286521:\n",
    "                #    continue\n",
    "                print(epoch, ix, ADD_MAX)\n",
    "                if ix + 1 > ADD_MAX:\n",
    "                    print(\"exit\")\n",
    "                    raise\n",
    "                dfwt = pd.read_parquet(f\"{DATA}/{CORRECT_HEAD_TIMING}/{epoch}.parquet\").drop_duplicates()\n",
    "                #dfwt.drop(\"event_date_time\", axis=1, inplace=True)\n",
    "                dfwt['event_date_time'] = dfwt['event_date_time'].apply(lambda x: parse_datetime(x))\n",
    "                dfwt[\"seconds_in_slot\"] = dfwt.apply(lambda x: get_time_in_curr_slot(x[\"event_date_time\"], x[\"slot\"]), axis=1)\n",
    "                dfwt.drop(\"event_date_time\", axis=1, inplace=True)\n",
    "                print(f\"adding {len(dfwt)} lines for epoch {epoch}\")\n",
    "                df = pd.concat([dfwt, df], ignore_index=True)\n",
    "                change = True\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    finally:\n",
    "        if change:\n",
    "            print(f\"storing dataset {DATA}/{TMP}/correct_{WHAT}_timing.parquet\")\n",
    "            df.drop_duplicates(inplace=True)\n",
    "            df.to_parquet(f\"{DATA}/{TMP}/correct_{WHAT}_timing.parquet\", index=False)\n",
    "            print(f\"{len(set(df.slot // 32))} epochs in total\")\n",
    "        else:\n",
    "            print(\"nothing changed\")\n",
    "        df = df[[\"slot\", \"attesting_validator_index\", \"seconds_in_slot\"]]\n",
    "        df.columns=[\"slot\", \"validator\", \"seconds_in_slot\"]\n",
    "        labels = get_labels(overwrite=OVERWRITE)\n",
    "        totals = get_totals(df.slot.max()//32, nlargest=30)\n",
    "        df, largest = merge_labels(df, labels, nlargest=30)\n",
    "        print(\"-\")\n",
    "        jj = pd.DataFrame()\n",
    "        for i in df.label.unique():\n",
    "            print(i, end=\"\\r\")\n",
    "            _df = df[df[\"label\"] == i].copy()\n",
    "            _df = _df.sample(n=min([15000, len(_df)]), random_state=42)\n",
    "            jj = pd.concat([jj,_df], ignore_index=True)  \n",
    "        return df, largest, totals, jj\n",
    "    \n",
    "if WHAT == \"head\":\n",
    "    gg, largest, totals, jj = get_timing_dataset()\n",
    "    print(f\"{gg.slot.nunique() // 32} epochs in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f12a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_best_performer_list():\n",
    "    DAYS = 3\n",
    "    df = read_df()\n",
    "    df = df[df[\"epoch\"] > df.epoch.max() - DAYS*225]\n",
    "    a1 = set(check_duties(df.epoch.min())[\"validator\"])\n",
    "    a2 = set(check_duties(df.epoch.max())[\"validator\"])\n",
    "    a0 = a1.intersection(a2)\n",
    "    al = sorted(a0 - set(df.validator.tolist()))\n",
    "    with open(f\"{DATA}/{TMP}/high_performers.txt\", \"w\") as file:\n",
    "        file.write(str(al))\n",
    "    print(\"best list created\")\n",
    "    \n",
    "if WHAT == \"head\":\n",
    "    if CREATE_BEST_LIST:\n",
    "        create_best_performer_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374e3766",
   "metadata": {},
   "source": [
    "## Best Performers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fdb538",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if WHAT == \"head\":\n",
    "    with open(f\"{DATA}/{TMP}/high_performers.txt\", \"r\") as file:\n",
    "        al = eval(file.read())\n",
    "\n",
    "    best = gg.groupby([\"validator\", \"label\"])[\"slot\"].nunique().reset_index().sort_values(\"slot\", ascending=False)\n",
    "\n",
    "    #best = best[best[\"slot\"] == best[\"slot\"].max()].reset_index(drop=True)\n",
    "\n",
    "    best = best[best[\"validator\"].isin(al)]\n",
    "    zeros = set(gg.label.unique())- set(best.label.unique())\n",
    "    for i in zeros:\n",
    "        best.loc[len(best), (\"label\", \"validator\", \"slot\")] = (i, 999999999999999, 0)\n",
    "\n",
    "    best = best.groupby(\"label\")[\"validator\"].nunique().reset_index().sort_values(\"validator\", ascending=False)\n",
    "    best = pd.merge(best, totals, how=\"left\", left_on=\"label\", right_on=\"label\")\n",
    "    best.dropna(inplace=True)\n",
    "    best[\"best_per\"] = best[\"validator_x\"] / best[\"validator_y\"] * 100\n",
    "\n",
    "    best.loc[best[\"label\"].isin(zeros), \"validator_x\"] = 0\n",
    "    best.loc[best[\"label\"].isin(zeros), \"best_per\"] = 0\n",
    "    _labels = set(best.label)\n",
    "    _largest = [i for i in largest if i in _labels]\n",
    "    best.set_index(\"label\", inplace=True)\n",
    "    best = best.loc[_largest]\n",
    "    best.reset_index(inplace=True)\n",
    "    best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96632f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if WHAT == \"head\":\n",
    "    table = best[[\"label\", \"validator_x\", \"validator_y\", \"best_per\"]]\n",
    "    table.columns = [\"Entity\", \"Nr. of<br>high-performing<br>Validators\", \"Total<br>Validators\", \"% of<br>high-performing<br>Validators\"]\n",
    "    table.set_index(\"Entity\", inplace=True)\n",
    "\n",
    "    # Apply rounding, type conversion, and thousand separators\n",
    "    for i in table.columns:\n",
    "        if \"%\" in i:\n",
    "            table[i] = table[i].apply(lambda x: round(x, 2))\n",
    "        else:\n",
    "            table[i] = table[i].apply(lambda x: \"{:,}\".format(x))\n",
    "\n",
    "    # Function to apply color formatting\n",
    "    def color_high_low(val):\n",
    "        color = ''\n",
    "        if isinstance(val, (int, float)):\n",
    "            if val > table[\"% of<br>high-performing<br>Validators\"].mean():\n",
    "                color = 'background-color: lightgreen'\n",
    "            elif val < table[\"% of<br>high-performing<br>Validators\"].mean():\n",
    "                color = 'background-color: lightcoral'\n",
    "        return color\n",
    "\n",
    "    # Apply the function to the last column using Styler.applymap\n",
    "    styled_table = table.style.applymap(color_high_low, subset=[\"% of<br>high-performing<br>Validators\"])\n",
    "\n",
    "    epoch_min = gg['slot'].min() // 32\n",
    "    epoch_max = gg['slot'].max() // 32\n",
    "    subtitle = f'''\n",
    "    ____________________________________________________<br>\n",
    "    <span style=\"font-size: 14px;font-family:Ubuntu mono\">epoch {epoch_min:,} - {epoch_max:,} ({(epoch_max-epoch_min)} epochs)<br>\n",
    "    high performer = validator with correct head votes for {3} days\n",
    "    </span>'''\n",
    "\n",
    "    # Use tabulate to print the table in markdown format with headers having line breaks\n",
    "    print(tabulate(table, headers='keys', tablefmt='pipe'))\n",
    "\n",
    "    # Convert the styled table to HTML and add the subtitle\n",
    "    styled_table_html = styled_table.set_table_styles([\n",
    "        {'selector': 'table', 'props': [('width', '100%'), ('font-size', '14pt')]},\n",
    "        {'selector': 'th, td', 'props': [('padding-right', '10px'), ('padding-left', '10px'), ('text-align', 'right'), ('font-size', '10pt')]},\n",
    "        {'selector': 'th', 'props': [('word-wrap', 'break-word'), ('white-space', 'normal'), ('font-size', '10pt')]}\n",
    "    ]).format({\n",
    "        \"% of<br>high-performing<br>Validators\": \"{:.2f}\"\n",
    "    }).to_html() + subtitle\n",
    "\n",
    "\n",
    "    # Optionally save the styled table to an HTML file\n",
    "    with open(f'{DATA}/{TMP}/performer_table.html', 'w') as f:\n",
    "        f.write(styled_table_html)\n",
    "\n",
    "    options = {\n",
    "        'width': '650',  # Set the desired width\n",
    "        'height': '770'  # Set the desired height\n",
    "    }\n",
    "\n",
    "    # Convert the HTML file to PNG using imgkit with specified options\n",
    "    imgkit.from_file(f'{DATA}/{TMP}/performer_table.html', f'{IMAGE}/performer_table.jpeg', options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75514f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_performer_share(best):\n",
    "    _best = best[[\"label\", \"best_per\"]].copy()\n",
    "    fig = go.Figure()\n",
    "    start_color = '#377eb8'\n",
    "    end_color = '#8cb6fa'\n",
    "\n",
    "    # Generate a gradient of 30 colors between the start and end colors\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"custom_gradient\", [start_color, end_color])\n",
    "    gradient = [mcolors.rgb2hex(cmap(i / 30)) for i in range(31)]\n",
    "\n",
    "    # If there are more than 30 bars, repeat the gradient\n",
    "    num_bars = len(_best)\n",
    "    colors = (gradient * ((num_bars // 31) + 1))[:num_bars]\n",
    "\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=_best[\"label\"],\n",
    "        y=_best[\"best_per\"],\n",
    "        marker=dict(color=colors),\n",
    "        name=None\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text=f'High Performers over Node Operators <span style=\"font-size: 16px;\">(epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})</span>',\n",
    "        legend=dict(x=0, y=1),\n",
    "        barmode='group',\n",
    "        legend_traceorder=\"reversed\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "            title=None,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=\"% high performers of total\",\n",
    "            showgrid=True,\n",
    "            gridcolor='lightgrey',\n",
    "        ),\n",
    "        height=550,\n",
    "        width=1200,\n",
    "        font=dict(\n",
    "            family=\"Ubuntu Mono\",\n",
    "            size=16,\n",
    "            color=\"black\"\n",
    "        ),\n",
    "        plot_bgcolor=\"#FFFFFF\"\n",
    "    )\n",
    "    return fig\n",
    "if WHAT == \"head\":\n",
    "    fig = high_performer_share(best)\n",
    "    fig.write_image(f\"{IMAGE}/topperformer_percentage.png\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c2c6f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def high_performer_vs_rest_timing(gg):\n",
    "    tt = gg.groupby([\"validator\"])[\"seconds_in_slot\"].median().reset_index().sort_values(\"seconds_in_slot\", ascending=False)\n",
    "\n",
    "    rr = gg.groupby([\"validator\", \"label\"])[\"slot\"].nunique().reset_index().sort_values(\"slot\", ascending=False)\n",
    "    rr = rr[rr[\"validator\"].isin(al)].reset_index(drop=True)\n",
    "    #rr = rr[rr[\"slot\"] == rr[\"slot\"].max()].reset_index(drop=True)\n",
    "    rr = pd.merge(rr, tt, how=\"left\", left_on=\"validator\", right_on=\"validator\")\n",
    "\n",
    "    #if not \"jj\" in globals():\n",
    "    #    jj = pd.DataFrame()\n",
    "    #    for i in gg.label.unique():\n",
    "    #        print(i, end=\"\\r\")\n",
    "    #        _df = gg[gg[\"label\"] == i].copy()\n",
    "    #        _df = _df.sample(n=min([1000, len(_df)]), random_state=42)\n",
    "    #        jj = pd.concat([jj,_df], ignore_index=True)  \n",
    "\n",
    "    def calculate_kde(data, x_range):\n",
    "        kde = gaussian_kde(data)\n",
    "        x = np.linspace(x_range[0], x_range[1], 1000)\n",
    "        y = kde(x)\n",
    "        return x, y\n",
    "\n",
    "    x_jj, y_jj = calculate_kde(jj['seconds_in_slot'], (0, 10))\n",
    "    x_rr, y_rr = calculate_kde(rr['seconds_in_slot'], (0, 10))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add KDE plot for the first dataset\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_jj,\n",
    "        y=y_jj,\n",
    "        fill='tozeroy',\n",
    "        mode='lines',\n",
    "        name='Rest',\n",
    "        line=dict(color=COLORS3[0]),\n",
    "        opacity=0.5\n",
    "    ))\n",
    "\n",
    "    # Add KDE plot for the second dataset\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=x_rr,\n",
    "        y=y_rr,\n",
    "        fill='tozeroy',\n",
    "        mode='lines',\n",
    "        name=f'High Performer (n={len(rr)})',\n",
    "        line=dict(color=COLORS3[1]),\n",
    "        opacity=0.5\n",
    "    ))\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "            title=f'Head Vote Timing (first seen) - High Performer vs. Rest <span style=\"font-size: 16px;\">(epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})</span>',\n",
    "            yaxis_title='density',\n",
    "            xaxis_title='seconds in slot',\n",
    "            barmode='stack',\n",
    "            legend_traceorder=\"normal\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "            ),\n",
    "            height=IMAGE_HEIGHT,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=FONTSIZE,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            legend=dict(\n",
    "                x=1,\n",
    "                y=1,\n",
    "                xanchor='right',\n",
    "                yanchor='top'\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "            #yaxis = dict(\n",
    "            #    type=\"log\"\n",
    "            #)\n",
    "        )\n",
    "\n",
    "    # Remove border (Plotly does not have a direct way to remove axis borders, so we set them to be invisible)\n",
    "    fig.update_xaxes(showline=False)\n",
    "    fig.update_yaxes(showline=False)\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = high_performer_vs_rest_timing(gg)\n",
    "    fig.write_image(f\"{IMAGE}/high_performer_vs_rest_timing.png\")\n",
    "    if SHOW:\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c339a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_joyplot(_jj, colormap, filename, _largest):\n",
    "    rr = _jj.copy()\n",
    "    \n",
    "    #rr.set_index(\"label\", inplace=True)\n",
    "    #rr = rr.loc[_largest]\n",
    "    #rr.reset_index(inplace=True)\n",
    "    rr['label'] = pd.Categorical(rr['label'], categories=_largest, ordered=True)\n",
    "    print(len(rr))\n",
    "    #rr = rr.sample(n=min([9790, len(rr)]), random_state=42)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 20))\n",
    "    \n",
    "    joyplot(\n",
    "        data=rr,\n",
    "        by='label',\n",
    "        overlap=0.5,\n",
    "        column='seconds_in_slot',\n",
    "        figsize=(12, 20),\n",
    "        colormap=colormap,\n",
    "        x_range=[0, 8],\n",
    "        alpha=0.5,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('seconds in slot')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.text(-0.95, 1.0, f'Head Vote Seen Timing over Seconds In Slot (epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})', fontsize=20, ha='left', va='top', fontweight='bold', fontfamily='Ubuntu Mono')\n",
    "\n",
    "    plt.savefig(filename, format='png', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def timing_head_votes_ridgelines(gg, al):\n",
    "    rr = gg.copy()\n",
    "    rr = rr[rr[\"validator\"].isin(al)].reset_index(drop=True)\n",
    "    \n",
    "    # Ensure that 'seconds_in_slot' is numeric\n",
    "    rr['seconds_in_slot'] = pd.to_numeric(rr['seconds_in_slot'], errors='coerce')\n",
    "\n",
    "    COLORS3 = [\n",
    "        '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628',\n",
    "        '#e41a1c', '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99',\n",
    "        '#cab2d6', '#1f78b4', '#33a02c', '#ff7f7f', '#8dd3c7', '#ffffb3',\n",
    "        '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5',\n",
    "        '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f',\n",
    "        '#6a3d9a', '#ffcc00', '#b15928', '#1f78b4', '#e31a1c', '#33a02c',\n",
    "        '#fb9a99', '#e6ab02', '#a6761d', '#666666'\n",
    "    ]\n",
    "\n",
    "    colors1 = [COLORS3[0], '#a3d6ff']\n",
    "    cmap1 = LinearSegmentedColormap.from_list('transition1', colors1, N=30)\n",
    "\n",
    "    colors2 = ['#ff7f00', '#ffd8b1']\n",
    "    cmap2 = LinearSegmentedColormap.from_list('transition2', colors2, N=30)\n",
    "\n",
    "    # Sort the DataFrame by 'label' while preserving the existing order\n",
    "    rr['label'] = pd.Categorical(rr['label'], categories=rr['label'].unique(), ordered=True)\n",
    "    rr_sorted = rr.sort_values('label')\n",
    "    \n",
    "    font_path = '/usr/share/fonts/truetype/dejavu/UbuntuMono-R.ttf'  # Update this with the actual path to the font file\n",
    "    font_manager.fontManager.addfont(font_path)\n",
    "    plt.rcParams['font.family'] = 'Ubuntu Mono'\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['axes.titlesize'] = 20\n",
    "    plt.rcParams['axes.labelsize'] = 16\n",
    "    plt.rcParams['xtick.labelsize'] = 14\n",
    "    plt.rcParams['ytick.labelsize'] = 14\n",
    "    labels = set(jj.label)\n",
    "    _largest = [i for i in largest if i in labels]\n",
    "    save_joyplot(jj, cmap1, f\"{DATA}/{TMP}/joyplot1.png\", _largest)\n",
    "    save_joyplot(rr, cmap2, f\"{DATA}/{TMP}/joyplot2.png\", _largest)\n",
    "\n",
    "\n",
    "def create_legend(output_path):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.axis('off')\n",
    "\n",
    "    rest_patch = mpatches.Patch(color='#377eb8', label='Rest', alpha=0.5)\n",
    "    high_perf_patch = mpatches.Patch(color='#ff7f00', label='High Performers', alpha=0.5)\n",
    "\n",
    "    ax.legend(handles=[high_perf_patch, rest_patch], loc='center', fontsize=24, frameon=True, framealpha=1)\n",
    "    plt.savefig(output_path, format='png', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def overlay_images(image1_path, image2_path, output_path):\n",
    "    image1 = Image.open(image1_path).convert(\"RGBA\")\n",
    "    image2 = Image.open(image2_path).convert(\"RGBA\")\n",
    "\n",
    "    combined = Image.alpha_composite(image1, image2)\n",
    "    combined.save(output_path)\n",
    "\n",
    "def overlay_legend(combined_image_path, legend_path, final_output_path):\n",
    "    combined_image = Image.open(combined_image_path).convert(\"RGBA\")\n",
    "    legend = Image.open(legend_path).convert(\"RGBA\")\n",
    "\n",
    "    # Resize legend if needed\n",
    "    legend = legend.resize((int(combined_image.width * 0.3), int(combined_image.height * 0.1)))\n",
    "    \n",
    "    legend_position = (combined_image.width - legend.width - 50, 25)\n",
    "\n",
    "    # Paste the legend on the combined image at a specified position\n",
    "    combined_image.paste(legend, (860,-20), legend)\n",
    "    combined_image.save(final_output_path)\n",
    "if WHAT == \"head\":\n",
    "    timing_head_votes_ridgelines(jj, al)\n",
    "    # Ensure the legend image is created and saved correctly\n",
    "    create_legend(f\"{DATA}/{TMP}/legend.png\")\n",
    "\n",
    "    # Overlay the saved joyplot images\n",
    "    overlay_images(f\"{DATA}/{TMP}/joyplot1.png\", f\"{DATA}/{TMP}/joyplot2.png\", f\"{DATA}/{TMP}/combined_joyplot.png\")\n",
    "\n",
    "    # Overlay the legend on the combined image\n",
    "    overlay_legend(f\"{DATA}/{TMP}/combined_joyplot.png\", f\"{DATA}/{TMP}/legend.png\", f\"{IMAGE}/ridgeline_timing.png\")\n",
    "\n",
    "    # Display the final combined image with legend\n",
    "    final_combined_image = Image.open(f\"{IMAGE}/ridgeline_timing.png\")\n",
    "    white_background = Image.new(\"RGBA\", final_combined_image.size, \"WHITE\")\n",
    "\n",
    "    # Paste the original image onto the white background\n",
    "    white_background.paste(final_combined_image, (0, 0), final_combined_image)\n",
    "\n",
    "    # Convert to RGB to remove the alpha channel\n",
    "    final_image_with_white_bg = white_background.convert(\"RGB\")\n",
    "\n",
    "    # Save the final image\n",
    "    final_image_with_white_bg.save(f\"{IMAGE}/ridgeline_timing_with_white_bg.png\")\n",
    "\n",
    "    # Display the final image\n",
    "    final_image_with_white_bg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08f9e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#clients_final = get_clients(overwrite=OVERWRITE)\n",
    "\n",
    "clients_final = get_clients(overwrite=False)\n",
    "if WHAT == \"head\":\n",
    "    \n",
    "    _gg = pd.merge(gg, clients_final, how=\"left\", left_on=\"validator\", right_on=\"validator_id\")\n",
    "    _jj = pd.merge(jj, clients_final, how=\"left\", left_on=\"validator\", right_on=\"validator_id\")\n",
    "    _jj.fillna(\"Unknown\", inplace=True)\n",
    "    _gg.fillna(\"Unknown\", inplace=True)\n",
    "    _jj = _jj[_jj[\"seconds_in_slot\"] <= 12]\n",
    "\n",
    "    cl_client_counts = _gg.groupby(\"cl_client\")[\"slot\"].count().to_dict()\n",
    "    _largest = [\"Lighthouse\", \"Prysm\", \"Teku\", \"Nimbus\", \"Lodestar\", \"Unknown\"]\n",
    "\n",
    "def save_joyplot(_jj, colormap, filename, _largest):\n",
    "    rr = _jj.copy()\n",
    "    \n",
    "    #rr.set_index(\"label\", inplace=True)\n",
    "    #rr = rr.loc[_largest]\n",
    "    #rr.reset_index(inplace=True)\n",
    "    rr['cl_client'] = pd.Categorical(rr['cl_client'], categories=_largest, ordered=True)\n",
    "    print(len(rr))\n",
    "    #rr = rr.sample(n=min([9790, len(rr)]), random_state=42)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    joyplot(\n",
    "        data=rr,\n",
    "        by='cl_client',\n",
    "        overlap=0.7,\n",
    "        column='seconds_in_slot',\n",
    "        figsize=(12, 6),\n",
    "        colormap=colormap,\n",
    "        x_range=[0, 8],\n",
    "        alpha=0.5,\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('seconds in slot')\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.text(-0.95, 1.0, f'Head Vote Seen Timing over Seconds In Slot (epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})', fontsize=20, ha='left', va='top', fontweight='bold', fontfamily='Ubuntu Mono')\n",
    "    for idx, client in enumerate(_largest):\n",
    "        count = cl_client_counts.get(client, 0)\n",
    "        plt.text(7, 0.78 - 0.145*idx, f\"n={count:,}\", fontsize=14, ha='left', va='center')\n",
    "\n",
    "    plt.savefig(filename, format='png', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def timing_head_votes_clients():\n",
    "\n",
    "    COLORS3 = [\n",
    "        '#377eb8', '#ff7f00', '#4daf4a', '#984ea3', '#f781bf', '#a65628',\n",
    "        '#e41a1c', '#a6cee3', '#999999', '#fdbf6f', '#b2df8a', '#fb9a99',\n",
    "        '#cab2d6', '#1f78b4', '#33a02c', '#ff7f7f', '#8dd3c7', '#ffffb3',\n",
    "        '#bebada', '#fb8072', '#80b1d3', '#fdb462', '#b3de69', '#fccde5',\n",
    "        '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f',\n",
    "        '#6a3d9a', '#ffcc00', '#b15928', '#1f78b4', '#e31a1c', '#33a02c',\n",
    "        '#fb9a99', '#e6ab02', '#a6761d', '#666666'\n",
    "    ]\n",
    "\n",
    "    colors1 = [COLORS3[0], '#a3d6ff']\n",
    "    cmap1 = LinearSegmentedColormap.from_list('transition1', colors1, N=30)\n",
    "\n",
    "    # Sort the DataFrame by 'label' while preserving the existing order\n",
    "    #_jj['label'] = pd.Categorical(_jj['label'], categories=_jj['label'].unique(), ordered=True)\n",
    "    #_jj_sorted = _jj.sort_values('label')\n",
    "    \n",
    "    font_path = '/usr/share/fonts/truetype/dejavu/UbuntuMono-R.ttf'  # Update this with the actual path to the font file\n",
    "    font_manager.fontManager.addfont(font_path)\n",
    "    plt.rcParams['font.family'] = 'Ubuntu Mono'\n",
    "    plt.rcParams['font.size'] = 14\n",
    "    plt.rcParams['axes.titlesize'] = 20\n",
    "    plt.rcParams['axes.labelsize'] = 16\n",
    "    plt.rcParams['xtick.labelsize'] = 14\n",
    "    plt.rcParams['ytick.labelsize'] = 14\n",
    "    cl_client = set(_jj.cl_client)\n",
    "    #_largest = _jj.cl_client.unique().tolist()\n",
    "    #save_joyplot(jj, cmap1, f\"{DATA}/{TMP}/joyplot1.png\", _largest)\n",
    "    save_joyplot(_jj, cmap1, f\"{IMAGE}/head_timing_cl_clients.png\", _largest)\n",
    "\n",
    "\n",
    "def create_legend(output_path):\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.axis('off')\n",
    "\n",
    "    rest_patch = mpatches.Patch(color='#377eb8', label='Rest', alpha=0.5)\n",
    "    high_perf_patch = mpatches.Patch(color='#ff7f00', label='High Performers', alpha=0.5)\n",
    "\n",
    "    ax.legend(handles=[high_perf_patch, rest_patch], loc='center', fontsize=24, frameon=True, framealpha=1)\n",
    "    plt.savefig(output_path, format='png', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def overlay_legend(combined_image_path, legend_path, final_output_path):\n",
    "    combined_image = Image.open(combined_image_path).convert(\"RGBA\")\n",
    "    legend = Image.open(legend_path).convert(\"RGBA\")\n",
    "\n",
    "    # Resize legend if needed\n",
    "    legend = legend.resize((int(combined_image.width * 0.3), int(combined_image.height * 0.1)))\n",
    "    \n",
    "    legend_position = (combined_image.width - legend.width - 50, 25)\n",
    "\n",
    "    # Paste the legend on the combined image at a specified position\n",
    "    combined_image.paste(legend, (860,-20), legend)\n",
    "    combined_image.save(final_output_path)\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    timing_head_votes_clients()\n",
    "    create_legend(f\"{DATA}/{TMP}/legend2.png\")\n",
    "\n",
    "\n",
    "    # Display the final combined image with legend\n",
    "    final_image = Image.open(f\"{IMAGE}/head_timing_cl_clients.png\")\n",
    "    final_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328b9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def attestations_cdf(gg):\n",
    "\n",
    "    data = gg.seconds_in_slot.tolist()[::100000]\n",
    "    data.sort()\n",
    "\n",
    "    data_array = np.array(data)\n",
    "\n",
    "    cum_freq = np.cumsum(np.ones_like(data_array))\n",
    "    cum_density = cum_freq / cum_freq[-1]\n",
    "\n",
    "    cumulative_density = list(zip(data_array, cum_density))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=data_array,\n",
    "        y=cum_density,\n",
    "        mode='lines',\n",
    "        name='Cumulative Density',\n",
    "        line=dict(color=COLORS[0], width=3),\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "            title=f'Cum. Distribution of Attestations First Seen Timing <span style=\"font-size: 16px;\">(epoch {gg.slot.min() //32:,} - {gg.slot.max() // 32:,})</span>',\n",
    "            yaxis_title='cumulative probability',\n",
    "            xaxis_title='seconds in slot',\n",
    "            barmode='stack',\n",
    "            legend_traceorder=\"normal\",\n",
    "            xaxis=dict(\n",
    "                tickmode='linear',\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=True,\n",
    "                gridcolor='lightgrey',\n",
    "            ),\n",
    "            height=IMAGE_HEIGHT,\n",
    "            width=1200,\n",
    "            font=dict(\n",
    "                family=\"Ubuntu Mono\",\n",
    "                size=FONTSIZE,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            legend=dict(\n",
    "                x=1,\n",
    "                y=1,\n",
    "                xanchor='right',\n",
    "                yanchor='top'\n",
    "            ),\n",
    "            plot_bgcolor = \"#FFFFFF\"\n",
    "            #yaxis = dict(\n",
    "            #    type=\"log\"\n",
    "            #)\n",
    "        )\n",
    "\n",
    "    # Remove border (Plotly does not have a direct way to remove axis borders, so we set them to be invisible)\n",
    "    #fig.update_xaxes(showline=False)\n",
    "    #fig.update_yaxes(showline=False)\n",
    "    return fig\n",
    "\n",
    "if WHAT == \"head\":\n",
    "    fig = attestations_cdf(gg)\n",
    "    fig.write_image(f\"{IMAGE}/attestations_cdf.png\")\n",
    "    if SHOW:\n",
    "        fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datanalysis",
   "language": "python",
   "name": "datanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
